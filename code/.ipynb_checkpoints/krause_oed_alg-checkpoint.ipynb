{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load in relevant packages\n",
    "%matplotlib inline\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('seaborn-whitegrid')\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import gpflow\n",
    "import math as ma\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "feature_scaler = StandardScaler()\n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "## set max number\n",
    "N = 25\n",
    "## set number of sensor locations to find\n",
    "k = 3\n",
    "## set percent of N to train on\n",
    "perc = .10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13f1d5f60>]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## create subset size for the trained data\n",
    "sub = ma.ceil(perc*N)\n",
    "## create fake data for model\n",
    "noiseSize = 0.05\n",
    "\n",
    "## define X values (integers from 20 to N+20)\n",
    "X_all = np.arange(20,20+N+1,1)\n",
    "## take sample for training\n",
    "x_train = np.random.randint(20,20+N+1,sub)\n",
    "x_train = x_train.reshape(-1,1)\n",
    "x_train = x_train.astype(float)\n",
    "y_train = np.sin(12*x_train) + 0.66*np.cos(25*x_train)  + np.random.randn(sub,1)*noiseSize + 3\n",
    "\n",
    "## plot distribution of selected sensors\n",
    "plt.plot(x_train, y_train, 'kx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>prior</th>\n",
       "      <th>transform</th>\n",
       "      <th>trainable</th>\n",
       "      <th>shape</th>\n",
       "      <th>fixed_shape</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GPR/kern/lengthscales</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPR/kern/variance</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPR/likelihood/variance</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             class prior transform  trainable shape  \\\n",
       "GPR/kern/lengthscales    Parameter  None       +ve       True    ()   \n",
       "GPR/kern/variance        Parameter  None       +ve       True    ()   \n",
       "GPR/likelihood/variance  Parameter  None       +ve       True    ()   \n",
       "\n",
       "                         fixed_shape value  \n",
       "GPR/kern/lengthscales           True   1.0  \n",
       "GPR/kern/variance               True   1.0  \n",
       "GPR/likelihood/variance         True  0.01  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## build model\n",
    "kernel = gpflow.kernels.RBF(1, active_dims=[0], lengthscales=1.0)\n",
    "## build model\n",
    "m = gpflow.models.GPR(x_train, y_train, kern=kernel)\n",
    "m.likelihood.variance = 0.01\n",
    "\n",
    "## view \n",
    "m.as_pandas_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 3.398231\n",
      "  Number of iterations: 31\n",
      "  Number of functions evaluations: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 3.398231\n",
      "  Number of iterations: 31\n",
      "  Number of functions evaluations: 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             class prior transform  trainable shape  \\\n",
      "GPR/kern/lengthscales    Parameter  None       +ve       True    ()   \n",
      "GPR/kern/variance        Parameter  None       +ve       True    ()   \n",
      "GPR/likelihood/variance  Parameter  None       +ve       True    ()   \n",
      "\n",
      "                         fixed_shape                value  \n",
      "GPR/kern/lengthscales           True    826.0590084529374  \n",
      "GPR/kern/variance               True   4.5809846002726555  \n",
      "GPR/likelihood/variance         True  0.11354623675206747  \n"
     ]
    }
   ],
   "source": [
    "gpflow.train.ScipyOptimizer().minimize(m)\n",
    "print(m.as_pandas_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "## example: thought exercise\n",
    "## 5 sensor locations: S = [4,5,6,7,8]\n",
    "## total number of sensors to find: k = 2\n",
    "## for each iteration (1:k):\n",
    "    ## for each possible sensor location (y) not in A (S):\n",
    "        ## calculate: corr(y)^2 - corr(yA)*np.linalg.inv(corr(AA))*corr(Ay) / corr(y)^2 - corr(ynA)*np.linalg.inv(corr(nAA))*corr(nAy)\n",
    "    ## select max(store_val)\n",
    "    ## append y to A\n",
    "\n",
    "    \n",
    "## selected sensors (indices)\n",
    "A = np.array([],dtype=int)\n",
    "## number of sensors to find\n",
    "k = k\n",
    "## define x_new as the new points not used for training\n",
    "x_new = np.setdiff1d(X_all, x_train)\n",
    "x_new = x_new.reshape(-1,1)\n",
    "## define S as the incides of x_new\n",
    "S = np.arange(0,x_new.shape[0]).reshape(x_new.shape[0],1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "## x is np.array or single value\n",
    "def generate_cov_mat(x):\n",
    "    if not isinstance(x, np.ndarray):\n",
    "        x = np.array(x).reshape(-1,1)\n",
    "    ## select the 2nd object and bring up one dimension\n",
    "    cov_mat = m.predict_f_full_cov(x)[1][0,:,:]\n",
    "    return(cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WORKS ONLY FOR 1-D DATA\n",
    "def plot_as_you_go(m, X_all, j, x_star, x_train, y_train, var_plot, X):\n",
    "    \n",
    "    ## where:\n",
    "    ## m = model object\n",
    "    ## x_all = all values of X\n",
    "    ## j = iteration of sensor being picked\n",
    "    ## x_star = best sensors picked so far\n",
    "    ## x_train = x training data\n",
    "    ## y_train = y training data\n",
    "    ## var_plot = variance of the measurements (calc_1)\n",
    "    ## X = the rest of the sample space (potential site points)\n",
    "    \n",
    "    ## true underlying function: dashed line\n",
    "    ## mean: green line\n",
    "    ## shade: sd\n",
    "    ## training points: black dots\n",
    "    ## selected sensor points: pink triangles\n",
    "    \n",
    "    ## so the footballs should be based on numerator, should match predicted variance in very beginning.\n",
    "    \n",
    "    ## define entire range of X\n",
    "    #xx = np.linspace(0, N, N+1)[:,None]\n",
    "    N = X.shape[0]\n",
    "    xx = X_all\n",
    "    ## actual function for entire range of X\n",
    "    yy = np.sin(12*xx) + 0.66*np.cos(25*xx)  + np.random.randn(N,1)*noiseSize + 3\n",
    "    \n",
    "    ## predict values for entire range of X\n",
    "    mean, var = m.predict_y(xx)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    ## display training data\n",
    "    #mean_train, var_train = m.predict_y(x_train)\n",
    "    #plt.plot(x_train, mean_train, 'ko', mew=2, alpha=0.55)\n",
    "    \n",
    "    ## display best sensors\n",
    "    #mean_sensors, var_sensors = m.predict_y(x_star)\n",
    "    ## plot the most recently added sensor darker than the others\n",
    "    #plt.plot(x_star[j], mean_sensors[j], color='m', marker='v', mew=2, alpha=1.0)\n",
    "    #plt.plot(x_star[0:j], mean_sensors[0:j], 'mv', mew=2, alpha=0.35)\n",
    "    \n",
    "    plt.plot(xx, yy, 'k--', alpha=0.5)\n",
    "    plt.plot(xx, mean, 'g', lw=2)\n",
    "    #plt.fill_between(xx[:,0], mean[:,0] - 2*np.sqrt(var_plot[:]), mean[:,0] + 2*np.sqrt(var_plot[:]), color='green', alpha=0.1)\n",
    "    plt.xlim(-1, max(X))\n",
    "    plt.title('Selected Sensors, N=' + str(N))\n",
    "    plt.savefig('../figures/selected_sensors_' + str(N) + ' k=' + str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_best_sensors_krause(S, X, k, A, x_train, y_train, m=m, N=N, X_all=X_all, verbose=False):\n",
    "\n",
    "    ## take out locations already in A before checks (iterations)\n",
    "    S = S[np.isin(S, A, invert=True)]\n",
    "    \n",
    "    ## checks\n",
    "    if k > S.shape[0]:\n",
    "        print(\"error! k must be smaller than S\")\n",
    "        return\n",
    "    if k/S.shape[0] > 0.25:\n",
    "        print(\"Recommendation: k should be a significantly small fraction of S\")\n",
    "    \n",
    "    ## print statements\n",
    "    print(\"finding \" + str(k) + \" sensor locations of \" + str(S.shape[0]) + \" possible locations\")\n",
    "    \n",
    "    ## next version: \n",
    "    ## add S + U\n",
    "    \n",
    "    ## later version:\n",
    "    ## create function to generate model\n",
    "    \n",
    "    ## for each sensor to be added:\n",
    "    for j in range(k):\n",
    "        ## find the indices of coordinates not already in A to iterate through\n",
    "        Y = S[np.isin(S, A, invert=True)]\n",
    "        ## store the calculated value for each potential coordinate in order to take the max\n",
    "        delta = np.array([])\n",
    "        var_plot = np.array([])\n",
    "        ## print iteration\n",
    "        print(\"Starting iteration: \" + str(j))\n",
    "    \n",
    "        for y in Y:\n",
    "            ## define how many sensor sites already exist\n",
    "            len_A = A.shape[0]\n",
    "            #print(\"length of A: \" + str(len_A))\n",
    "            ## combine indices of y and A\n",
    "            yA = np.append(np.array([y]), A, axis=0)\n",
    "            #print(\"yA: \" + str(yA))\n",
    "            ## collect values of y and A using the indices\n",
    "            yA_val = X[yA,:].reshape(yA.shape[0],X.shape[1])\n",
    "            #print(\"yA_val: \" + str(yA_val))\n",
    "            \n",
    "            ## define the rest of possible sites taking out y and A\n",
    "            nyA = S[np.isin(S, yA, invert=True)]\n",
    "            len_nA = nyA.shape[0]\n",
    "            #print(\"length of nA: \" + str(len_nA))\n",
    "            ## define the indices of locations not in yA\n",
    "            nyA = np.append(np.array([y]), nyA, axis=0)\n",
    "            #print(\"nyA: \" + str(nyA))\n",
    "            ## collect values of y and nA using the indices\n",
    "            nyA_val = X[nyA,:].reshape(nyA.shape[0],X.shape[1])\n",
    "            #print(\"nyA_val: \" + str(nyA_val))\n",
    "\n",
    "            ## generate the covariance matrix:\n",
    "            ##    y  A1  A2  ...\n",
    "            ## y\n",
    "            ## A1\n",
    "            ## A2\n",
    "            ## ...\n",
    "            cov_mat_A = generate_cov_mat(yA_val)\n",
    "            ## select y's covariance\n",
    "            y_cov = cov_mat_A[:1,[0]]\n",
    "            ## grab covariance values\n",
    "            if len_A > 0:\n",
    "                yA_cov = cov_mat_A[[0],1:len_A+1]\n",
    "                Ay_cov = yA_cov.T\n",
    "                AA_cov = cov_mat_A[1:len_A+1, 1:len_A+1]\n",
    "                ## Mz = x, give M and x and solve for z\n",
    "                AA_cov_inv = np.linalg.solve(AA_cov, Ay_cov)\n",
    "                calc_1 = y_cov**2 - np.dot(yA_cov, AA_cov_inv)\n",
    "                ## old code:\n",
    "                #AA_cov = np.linalg.inv(cov_mat_A[1:len_A+1, 1:len_A+1])\n",
    "                #calc_1 = y_cov**2 - np.dot(np.dot(yA_cov, AA_cov), Ay_cov)\n",
    "            ## if A is empty: ignore the 2nd part of the calculation\n",
    "            else:\n",
    "                calc_1 = y_cov**2\n",
    "            \n",
    "            cov_mat_nA = generate_cov_mat(nyA_val)\n",
    "            #print(\"cov_mat_nA: \")\n",
    "            #print(cov_mat_nA)\n",
    "            nyA_cov = cov_mat_nA[[0],1:len_nA+1]\n",
    "            #print(\"nyA_cov: \")\n",
    "            #print(nyA_cov)\n",
    "            nAy_cov = nyA_cov.T\n",
    "            nAA_cov = cov_mat_nA[1:len_nA+1, 1:len_nA+1]\n",
    "            #print(\"nAA_cov: \")\n",
    "            #print(nAA_cov)\n",
    "            ## Mz = x, give M and x and solve for z\n",
    "            nAA_cov_inv = np.linalg.solve(nAA_cov, nAy_cov)\n",
    "            calc_2 = y_cov**2 - np.dot(nyA_cov, nAA_cov_inv)\n",
    "            ## old code:\n",
    "            #nAA_cov = np.linalg.inv(cov_mat_nA[1:len_nA+1, 1:len_nA+1])\n",
    "            #calc_2 = y_cov**2 - np.dot(np.dot(nyA_cov, nAA_cov), nAy_cov)\n",
    "            \n",
    "            value = calc_1 / calc_2\n",
    "            delta = np.append(delta, value)\n",
    "            \n",
    "            var_plot = np.append(var_plot, calc_1)\n",
    "            \n",
    "        ## find the index with the largest delta\n",
    "        y_star = np.array(Y[np.argmax(delta)])\n",
    "        ## append to A as a new sensor site\n",
    "        A = np.append(A, y_star)\n",
    "        \n",
    "        ## generate plot for each iteration\n",
    "        plot_as_you_go(m, X_all=X_all, j=j-1, x_star=X[A,:], x_train=x_train, y_train=y_train, var_plot=var_plot, X=Y.reshape(Y.shape[0],1))\n",
    "        \n",
    "        if verbose == True:\n",
    "            #print(Y)\n",
    "            #print(delta)\n",
    "            print(\"Max value: \" + str(np.amax(delta)))\n",
    "            print(\"Picking sensor site: \" + str(y_star))\n",
    "    \n",
    "    A_sites = X[A,:]\n",
    "    return(A_sites, var_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23.]\n",
      " [34.]\n",
      " [35.]]\n",
      "25\n",
      "[35.]\n"
     ]
    }
   ],
   "source": [
    "#print(S)\n",
    "#print(x_new)\n",
    "print(x_train)\n",
    "print(N)\n",
    "print(max(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding 3 sensor locations of 23 possible locations\n",
      "Starting iteration: 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (26,) for Tensor 'autoflow/GPR/predict_y_48/Placeholder:0', which has shape '(?, ?)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-280-ff1f660c923a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_sensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpick_best_sensors_krause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_sensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_plot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-277-6cb69cd30e79>\u001b[0m in \u001b[0;36mpick_best_sensors_krause\u001b[0;34m(S, X, k, A, x_train, y_train, m, N, X_all, verbose)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m## generate plot for each iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mplot_as_you_go\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_star\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_plot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-276-68af829f3da2>\u001b[0m in \u001b[0;36mplot_as_you_go\u001b[0;34m(m, X_all, j, x_star, x_train, y_train, var_plot, X)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m## predict values for entire range of X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/gpflow/decors.py\u001b[0m in \u001b[0;36mautoflow_wrapper\u001b[0;34m(obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0m_setup_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0maf_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0maf_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0m_build_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_session_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mautoflow_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mautoflow_wrapper_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/gpflow/decors.py\u001b[0m in \u001b[0;36m_session_run\u001b[0;34m(session, obj, store, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0minitialize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'initialize'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'result'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1128\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1129\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (26,) for Tensor 'autoflow/GPR/predict_y_48/Placeholder:0', which has shape '(?, ?)'"
     ]
    }
   ],
   "source": [
    "best_sensors, var_plot = pick_best_sensors_krause(S=S, X=x_new, k=k, A=A, x_train=x_train, y_train=y_train, m=m, N=N, X_all=X_all, verbose=False)\n",
    "print(best_sensors)\n",
    "print(var_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrianna/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in sqrt\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(var_plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Original plot\n",
    "## WORKS ONLY FOR 1-D DATA\n",
    "def plot(m, N):\n",
    "    ## true underlying function: dashed line\n",
    "    ## mean: green line\n",
    "    ## shade: sd\n",
    "    ## training points: black dots\n",
    "    ## selected sensor points: red triangles\n",
    "    xx = np.linspace(0, N, N+1)[:,None]\n",
    "    ## actual function\n",
    "    yy = np.sin(12*xx) + 0.66*np.cos(25*xx)  + np.random.randn(N+1,1)*noiseSize + 3\n",
    "    ## predict values\n",
    "    mean, var = m.predict_y(xx)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    mean_train, var_train = m.predict_y(x_train)\n",
    "    plt.plot(x_train, mean_train, 'ko', mew=2)\n",
    "    \n",
    "    mean_sensors, var_sensors = m.predict_y(best_sensors)\n",
    "    plt.plot(best_sensors, mean_sensors, 'rv', mew=2)\n",
    "    \n",
    "    plt.plot(xx, yy, 'k--', alpha=0.5)\n",
    "    plt.plot(xx, mean, 'g', lw=2)\n",
    "    plt.fill_between(xx[:,0], mean[:,0] - 2*np.sqrt(var[:,0]), mean[:,0] + 2*np.sqrt(var[:,0]), color='green', alpha=0.1)\n",
    "    plt.xlim(0, N)\n",
    "    plt.title('Selected Sensors, N=' + str(N))\n",
    "    plt.savefig('../figures/selected_sensors_' + str(N))\n",
    "plot(m, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_new.shape[1])\n",
    "#print(x_new[0:5,:].reshape(5,1))\n",
    "## combine indices of y and A\n",
    "#yA = np.append(np.array([y]), A, axis=0)\n",
    "## collect values of y and A using the indices\n",
    "#yA_val = X[yA,:].reshape(yA.shape[0],X.shape[1])\n",
    "\n",
    "#print(m.as_pandas_table())\n",
    "#cov_mat_A = generate_cov_mat(x_new[0:5,:].reshape(5,1))\n",
    "#print(cov_mat_A)\n",
    "\n",
    "#m.likelihood.variance = 0.01\n",
    "#print(m.as_pandas_table())\n",
    "#cov_mat_A = generate_cov_mat(x_new[0:5,:].reshape(5,1))\n",
    "#print(cov_mat_A)\n",
    "\n",
    "## Try, artificially: (i) putting the input locations *very* close together;\n",
    "## and (ii) increasing the correlation lengths.\n",
    "## Keep the likelihood variance zero while you're at it.\n",
    "## Could you extract the eigenvalues of the matrix that's causing a problem and list them?\n",
    "## How small is the smallest eigenvalue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 7.599100\n",
      "  Number of iterations: 17\n",
      "  Number of functions evaluations: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 7.599100\n",
      "  Number of iterations: 17\n",
      "  Number of functions evaluations: 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             class prior transform  trainable shape  \\\n",
      "GPR/kern/lengthscales    Parameter  None       +ve       True    ()   \n",
      "GPR/kern/variance        Parameter  None       +ve       True    ()   \n",
      "GPR/likelihood/variance  Parameter  None       +ve       True    ()   \n",
      "\n",
      "                         fixed_shape               value  \n",
      "GPR/kern/lengthscales           True  1.0000000000000304  \n",
      "GPR/kern/variance               True   3.956615773239524  \n",
      "GPR/likelihood/variance         True  1.3958283825296467  \n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([[0,.00000001,.00000002,.00000003], [0,.00000002,.00000003,.00000001]]).reshape(4,2)\n",
    "y_train = np.array([1.3, 2.4, 3.6, 1.0]).reshape(4,1)\n",
    "\n",
    "## build model\n",
    "kernel = gpflow.kernels.RBF(2, active_dims=[0,1], lengthscales=1.0)\n",
    "\n",
    "## build model\n",
    "m = gpflow.models.GPR(x_train, y_train, kern=kernel)\n",
    "m.likelihood.variance = 0.01\n",
    "\n",
    "gpflow.train.ScipyOptimizer().minimize(m)\n",
    "print(m.as_pandas_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m.kern.lengthscales = 5\n",
    "#m.kern.variance = 0\n",
    "#m.likelihood.variance = 0\n",
    "#print(m.as_pandas_table())\n",
    "\n",
    "nyA_val = np.array([[0,.00000001,.00000002,.00000002], [0,.00000002,.00000003,.00000003]]).reshape(4,2)\n",
    "#np.array([[0,.00000001,.00000002,.00000003], [0.00000003, 0.00000002, 0.00000000, 0]]).reshape(4,2)\n",
    "cov_mat_nA = generate_cov_mat(nyA_val)\n",
    "print(cov_mat_nA)\n",
    "print(np.linalg.det(cov_mat_nA))\n",
    "eig_val = np.linalg.eig(cov_mat_nA)\n",
    "eig_val = eig_val[0]\n",
    "print(eig_val.shape)\n",
    "print(np.amin(eig_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fake data\n",
    "## random int X and NO2 concentration Y works!\n",
    "#X = np.random.randint(50, size=(20, 2)).astype(float)\n",
    "## so does this...\n",
    "#X = np.random.normal(size=(20,2))\n",
    "#print(X.shape)\n",
    "#print(X)\n",
    "#dta = pd.read_csv(\"../data/kcl_london_model_data_winter_collapsed.csv\", sep=',') \n",
    "#y = dta.loc[:,'nox'].values\n",
    "#y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 6)\n"
     ]
    }
   ],
   "source": [
    "## aggregated over time\n",
    "dta = pd.read_csv(\"../data/kcl_london_model_data_winter_collapsed.csv\", sep=',') \n",
    "print(dta.shape)\n",
    "params = ['latitude', 'longitude']\n",
    "\n",
    "#dta = pd.read_csv(\"../data/kcl_london_model_data_winter_agg_time.csv\", sep=',')\n",
    "#print(dta.shape)\n",
    "#params = ['latitude', 'longitude', 'year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "212\n",
      "(212, 6)\n"
     ]
    }
   ],
   "source": [
    "print(dta.shape[0])\n",
    "print(dta[params].drop_duplicates().shape[0])\n",
    "dta = dta.drop_duplicates(params)\n",
    "print(dta.shape)\n",
    "#print(X.shape)\n",
    "#unique_elements = np.unique(X)\n",
    "#print(unique_elements[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212, 2)\n",
      "(212, 1)\n"
     ]
    }
   ],
   "source": [
    "X = dta[params].values\n",
    "print(X.shape)\n",
    "## rescale lat/long and year data\n",
    "## scaling the data causes the determinant to be 0 for the matrix\n",
    "#X = feature_scaler.fit_transform(X)\n",
    "y = dta.loc[:,'nox'].values\n",
    "y = y.reshape(-1,1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set max number\n",
    "N = 212\n",
    "## set number of sensor locations to find\n",
    "k = 5\n",
    "## set percent of N to train on\n",
    "perc = .10\n",
    "#perc = .75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "## subset to the trained data\n",
    "sub = ma.ceil(perc*N)\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]\n"
     ]
    }
   ],
   "source": [
    "## take the first sub coordinates for training\n",
    "x_samps = np.arange(0,sub)\n",
    "print(x_samps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X[x_samps,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 2)\n",
      "(22, 1)\n"
     ]
    }
   ],
   "source": [
    "## take sample for training\n",
    "#x_samps = np.random.randint(X.shape[0], size=sub)\n",
    "\n",
    "x_train = X[x_samps,:]\n",
    "y_train = y[x_samps,:]\n",
    "## standardize y-values\n",
    "y_train = feature_scaler.fit_transform(y_train)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>prior</th>\n",
       "      <th>transform</th>\n",
       "      <th>trainable</th>\n",
       "      <th>shape</th>\n",
       "      <th>fixed_shape</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GPR/kern/lengthscales</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPR/kern/variance</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPR/likelihood/variance</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             class prior transform  trainable shape  \\\n",
       "GPR/kern/lengthscales    Parameter  None       +ve       True    ()   \n",
       "GPR/kern/variance        Parameter  None       +ve       True    ()   \n",
       "GPR/likelihood/variance  Parameter  None       +ve       True    ()   \n",
       "\n",
       "                         fixed_shape value  \n",
       "GPR/kern/lengthscales           True   1.0  \n",
       "GPR/kern/variance               True   1.0  \n",
       "GPR/likelihood/variance         True  0.01  "
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## build model\n",
    "kernel = gpflow.kernels.RBF(2, active_dims=[0,1], lengthscales=1.0)\n",
    "#kernel = gpflow.kernels.RBF(2, active_dims=[0,1], lengthscales=1.0) *\\\n",
    "#            gpflow.kernels.RBF(1 , active_dims=[2], lengthscales=0.1)\n",
    "\n",
    "## build model\n",
    "m = gpflow.models.GPR(x_train, y_train, kern=kernel)\n",
    "m.likelihood.variance = 0.01\n",
    "\n",
    "## could put bounds on likelihood variance to never be below or equal to 0.\n",
    "\n",
    "\n",
    "## view \n",
    "m.as_pandas_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 24.281726\n",
      "  Number of iterations: 39\n",
      "  Number of functions evaluations: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 24.281726\n",
      "  Number of iterations: 39\n",
      "  Number of functions evaluations: 58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             class prior transform  trainable shape  \\\n",
      "GPR/kern/lengthscales    Parameter  None       +ve       True    ()   \n",
      "GPR/kern/variance        Parameter  None       +ve       True    ()   \n",
      "GPR/likelihood/variance  Parameter  None       +ve       True    ()   \n",
      "\n",
      "                         fixed_shape                 value  \n",
      "GPR/kern/lengthscales           True  0.041672003238773805  \n",
      "GPR/kern/variance               True    0.8373748065039799  \n",
      "GPR/likelihood/variance         True   0.10317750005748468  \n"
     ]
    }
   ],
   "source": [
    "## Run Model\n",
    "## Marginal Liklihood Maximization\n",
    "## picks the most simple model that picks the data the best\n",
    "gpflow.train.ScipyOptimizer().minimize(m)\n",
    "print(m.as_pandas_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40\n",
      "  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58\n",
      "  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76\n",
      "  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94\n",
      "  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112\n",
      " 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130\n",
      " 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148\n",
      " 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166\n",
      " 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184\n",
      " 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202\n",
      " 203 204 205 206 207 208 209 210 211]\n",
      "(189, 2)\n",
      "[[51.52236671 -0.1547    ]\n",
      " [51.52250936 -0.15462215]\n",
      " [51.52254    -0.15459   ]\n",
      " [51.51392874 -0.1527927 ]\n",
      " [51.35865961 -0.14972395]]\n"
     ]
    }
   ],
   "source": [
    "## define x-values not used for training\n",
    "## iterate all of X\n",
    "#X_iter = np.arange(0,X.shape[0])\n",
    "## take out the iters already used for training\n",
    "#x_new = np.setdiff1d(X_iter, x_samps)\n",
    "#sub+2+N+1\n",
    "x_new_samps = np.arange(sub+1,212)\n",
    "#x_new_samps = np.arange(sub+20, sub+30+20)\n",
    "print(x_new_samps)\n",
    "## randomly select new iterations from the list\n",
    "#x_new_samps = np.random.choice(x_new, N-sub, replace=False)\n",
    "#print(x_samps)\n",
    "#print(x_new_samps)\n",
    "x_new = X[x_new_samps,:]\n",
    "print(x_new.shape)\n",
    "print(x_new[0:5])\n",
    "#print(x_samps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "## selected sensors (indices)\n",
    "A = np.array([],dtype=int)\n",
    "## number of sensors to find\n",
    "k = k\n",
    "## define S as the incides of x_new\n",
    "S = np.arange(0,x_new.shape[0]).reshape(x_new.shape[0],1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "## x is np.array or single value\n",
    "def generate_cov_mat(x):\n",
    "    if not isinstance(x, np.ndarray):\n",
    "        x = np.array(x).reshape(-1,1)\n",
    "    cov_mat = m.predict_f_full_cov(x)[1][0,:,:] #+ (identity * likelihood variance)\n",
    "    eig_val = np.linalg.eigvals(cov_mat)\n",
    "    #print(eig_val)\n",
    "    #eig_val = eig_val[0]\n",
    "    #print(np.amin(eig_val))\n",
    "    return(cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(189, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_new.shape)\n",
    "#print(X[0,:])\n",
    "m.likelihood.variance = 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "test = np.array([[1,2,3,4], [4,5,2,-1]]).reshape(4,2)\n",
    "print(np.amin(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_best_sensors_krause(S, X, k, A, verbose=False):\n",
    "\n",
    "    ## take out locations already in A before checks\n",
    "    S = S[np.isin(S, A, invert=True)]\n",
    "    \n",
    "    ## collect determinants\n",
    "    det = np.array([])\n",
    "    \n",
    "    ## checks\n",
    "    if k > S.shape[0]:\n",
    "        print(\"error! k must be smaller than S\")\n",
    "        return\n",
    "    if k/S.shape[0] > 0.25:\n",
    "        print(\"Recommendation: k should be a significantly small fraction of S\")\n",
    "    \n",
    "    ## print statements\n",
    "    print(\"finding \" + str(k) + \" sensor locations of \" + str(S.shape[0]) + \" possible locations\")\n",
    "    \n",
    "    ## next version: \n",
    "    ## add S + U\n",
    "    \n",
    "    ## later version:\n",
    "    ## create function to generate model\n",
    "    \n",
    "    ## add order of points selected\n",
    "    ## generate plots as it selects sensors \n",
    "    ## so the footballs should be based on numerator, should match predicted variance in very beginning.\n",
    "    \n",
    "    ## for each sensor to be added:\n",
    "    for j in range(k):\n",
    "        ## find the indices of coordinates not already in A to iterate through\n",
    "        Y = S[np.isin(S, A, invert=True)]\n",
    "        ## store the calculated value for each potential coordinate in order to take the max\n",
    "        delta = np.array([])\n",
    "        var_plot = np.array([])\n",
    "        ## print iteration\n",
    "        print(\"Starting iteration: \" + str(j))\n",
    "    \n",
    "        for y in Y:\n",
    "            ## define how many sensor sites already exist\n",
    "            len_A = A.shape[0]\n",
    "            ## combine indices of y and A\n",
    "            yA = np.append(np.array([y]), A, axis=0)\n",
    "            ## collect values of y and A using the indices\n",
    "            yA_val = X[yA,:].reshape(yA.shape[0],X.shape[1])\n",
    "            \n",
    "            ## define the rest of possible sites taking out y and A\n",
    "            nyA = S[np.isin(S, yA, invert=True)]\n",
    "            len_nA = nyA.shape[0]\n",
    "            ## define the indices of locations not in yA\n",
    "            nyA = np.append(np.array([y]), nyA, axis=0)\n",
    "            ## collect values of y and nA using the indices\n",
    "            nyA_val = X[nyA,:].reshape(nyA.shape[0],X.shape[1])\n",
    "\n",
    "            ## generate the covariance matrix:\n",
    "            ##    y  A1  A2  ...\n",
    "            ## y\n",
    "            ## A1\n",
    "            ## A2\n",
    "            ## ...\n",
    "            cov_mat_A = generate_cov_mat(yA_val)\n",
    "            ## select y's covariance\n",
    "            y_cov = cov_mat_A[:1,[0]]\n",
    "            ## grab covariance values\n",
    "            if len_A > 0:\n",
    "                yA_cov = cov_mat_A[[0],1:len_A+1]\n",
    "                Ay_cov = yA_cov.T\n",
    "                AA_cov = cov_mat_A[1:len_A+1, 1:len_A+1]\n",
    "                ## Mz = x, give M and x and solve for z\n",
    "                AA_cov_inv = np.linalg.solve(AA_cov, Ay_cov)\n",
    "                calc_1 = y_cov**2 - np.dot(yA_cov, AA_cov_inv)\n",
    "                ## old code:\n",
    "                #AA_cov = np.linalg.inv(cov_mat_A[1:len_A+1, 1:len_A+1])\n",
    "                #calc_1 = y_cov**2 - np.dot(np.dot(yA_cov, AA_cov), Ay_cov)\n",
    "            ## if A is empty: ignore the 2nd part of the calculation\n",
    "            else:\n",
    "                calc_1 = y_cov**2\n",
    "            \n",
    "            cov_mat_nA = generate_cov_mat(nyA_val)\n",
    "            nyA_cov = cov_mat_nA[[0],1:len_nA+1]\n",
    "            nAy_cov = nyA_cov.T\n",
    "            nAA_cov = cov_mat_nA[1:len_nA+1, 1:len_nA+1]\n",
    "            ## Mz = x, give M and x and solve for z\n",
    "            #print(nAA_cov)\n",
    "            nAA_cov_inv = np.linalg.solve(nAA_cov, nAy_cov)\n",
    "            calc_2 = y_cov**2 - np.dot(nyA_cov, nAA_cov_inv)\n",
    "            ## old code:\n",
    "            #nAA_cov = np.linalg.inv(cov_mat_nA[1:len_nA+1, 1:len_nA+1])\n",
    "            #calc_2 = y_cov**2 - np.dot(np.dot(nyA_cov, nAA_cov), nAy_cov)\n",
    "            \n",
    "            value = calc_1 / calc_2\n",
    "            delta = np.append(delta, value)\n",
    "\n",
    "        ## find the index with the largest delta\n",
    "        y_star = np.array(Y[np.argmax(delta)])\n",
    "        ## append to A as a new sensor site\n",
    "        A = np.append(A, y_star)\n",
    "        \n",
    "        if verbose == True:\n",
    "            #print(Y)\n",
    "            #print(delta)\n",
    "            print(\"Max value: \" + str(np.amax(delta)))\n",
    "            print(\"Picking sensor site: \" + str(y_star))\n",
    "    \n",
    "    A_sites = X[A,:]\n",
    "    return(A_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m.likelihood.variance = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding 5 sensor locations of 189 possible locations\n",
      "Starting iteration: 0\n",
      "Starting iteration: 1\n",
      "Starting iteration: 2\n",
      "Starting iteration: 3\n",
      "Starting iteration: 4\n"
     ]
    }
   ],
   "source": [
    "#print(S.shape)\n",
    "#print(x_new.shape)\n",
    "best_sensors= pick_best_sensors_krause(S=S, X=x_new, k=k, A=A, verbose=False)\n",
    "#print(best_sensors)\n",
    "#print(var_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.15522640e+01 -4.02779000e-01]\n",
      " [ 5.16686433e+01 -2.20072056e-02]\n",
      " [ 5.15207875e+01  2.05460706e-01]\n",
      " [ 5.15884170e+01 -3.62989000e-01]\n",
      " [ 5.16173270e+01 -2.98775000e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(best_sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
