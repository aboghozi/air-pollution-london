{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load in relevant packages\n",
    "%matplotlib inline\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('seaborn-whitegrid')\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import gpflow\n",
    "import math as ma\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "feature_scaler = StandardScaler()\n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "## setting to include the trained sensor points\n",
    "#include_trained = False\n",
    "## set max number\n",
    "N = 50\n",
    "## set number of sensor locations to find\n",
    "k = 20\n",
    "## set percent of N to train on\n",
    "perc = .10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEOZJREFUeJzt3XuMXPdZxvHvQ51yUdIbWUpIYoy4FYRoAru0KEhkQbThIgoSGi4lQFQUGBWUSBENRDIXGyTYinBRxEShgRQRUUbEgjbiFsFAFVWEXRs3TmwugUBJY4hLgQSQQCYvf+zYrNe7O7P2eGf25+9HWnnmnNczj4/sZ49/e2YmVYUkqS2fMO0AkqTJs9wlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWrQyHJPcn2SQZLjSZ5OcscGM69O8oEkHx7O3HZp4kqSxpFRr1BNcg1wTVUdSXIVcBj4pqo6vmbmHuDVVXV3kjngr4BPr6r/2exxr7766tq3b98k/gySdNk4fPjwx6pqbtTcnlEDVXUSODm8/VKSE8C1wPG1Y8BVSQJcCXwcOL3V4+7bt4+VlZVRTy9JWiPJP4wzN7Lc1z3oPuBG4Il1u+4D3g88D1wFfGtVvbydx5YkTc7YP1BNciXwCHBnVb24bvdbgaPAZwA3APcledUGj3F7kpUkK6dOnbqI2JKkrYxV7kmuYLXYH66qQxuM3AYcqlXPAM8Cb1g/VFUPVNV8Vc3PzY1cMpIkXaBxrpYJ8CBwoqru3WTsI8BXD+dfD3w+8HeTCilJ2p5x1txvAm4FjiU5Otx2D7AXoKruBw4CDyU5BgS4u6o+dgnySpLGMM7VMo+zWthbzTwPvGVSoSTNhqWlJRYWFlhcXDy7bTAYsLy8zLve9a4pJtMovkJV0qYWFhbodDoMBgNgtdg7nQ4LCwtTTqZRtnUppKTLy+LiIv1+n06nQ7fbpdfr0e/3zzmT12zyzF3SlhYXF+l2uxw8eJBut2ux7xKWu6QtDQYDer0e+/fvp9frnV2i0Wyz3CVt6swae7/f58CBA2eXaCz42We5S9rU8vLyOWvsZ9bgl5eXp5xMo4x8V8hLZX5+vnzjMEnaniSHq2p+1Jxn7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZJ2wNLS0nnvyTMYDFhaWrokz2e5S9IO2OkPPvHDOiRpB+z0B5945i5JO2QnP/jEcpekHbKTH3xiuUvSDtjpDz6x3CVpB+z0B5/4YR2StIv4YR2SdBmz3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDRpZ7kuuTDJIcT/J0kjs2mbs5ydHhzJ9OPqokaVzjvCvkaeCuqjqS5CrgcJLHqur4mYEkrwF+Cbilqj6S5NMuUV5J0hhGnrlX1cmqOjK8/RJwArh23dh3AIeq6iPDuRcmHVSSNL5trbkn2QfcCDyxbtfnAa9N8idJDif5rk1+/+1JVpKsnDp16kLySpLGMHa5J7kSeAS4s6peXLd7D/ClwNcDbwX2J/m89Y9RVQ9U1XxVzc/NzV1EbEnSVsb6JKYkV7Ba7A9X1aENRp4D/qWq/hP4zyQfBN4I/PXEkkqSxjbO1TIBHgROVNW9m4z9DvAVSfYk+RTgTayuzUuSpmCcM/ebgFuBY0mODrfdA+wFqKr7q+pEkt8HngReBt5TVU9disCSpNFGlntVPQ5kjLl3A++eRChJ0sXxFaqS1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQSPLPcn1SQZJjid5OskdW8wuJDmd5FsmG1OStB17xpg5DdxVVUeSXAUcTvJYVR1fO5TkFcDPAH94CXJKkrZh5Jl7VZ2sqiPD2y8BJ4BrNxj9QeAR4IWJJpQkbdu21tyT7ANuBJ5Yt/1a4JuB3qSCSZIu3NjlnuRKVs/M76yqF9ft/nng7qp6ecRj3J5kJcnKqVOntp9WkjSWVNXooeQK4FHgD6rq3g32PwtkePdq4L+A26vqtzd7zPn5+VpZWbmg0JJ0uUpyuKrmR82N/IFqkgAPAic2KnaAqvqsNfMPAY9uVeySpEtrnKtlbgJuBY4lOTrcdg+wF6Cq7r9E2SRJF2hkuVfV4/z/kstIVfU9FxNIknTxfIWqJDXIcpekBlnuktQgy12SGmS5S1KDLHdJatBlWe5LS0sMBoNztg0GA5aWlqaUSJIm67Is94WFBTqdztmCHwwGdDodFhYWppxMkiZjnFeoNmdxcZF+v0+n06Hb7dLr9ej3+ywuLk47miRNxGV55g6rBd/tdjl48CDdbtdil9SUy7bcB4MBvV6P/fv30+v1zluDl6Td7LIs9zNr7P1+nwMHDpxdorHgJbXisiz35eXlc9bYz6zBLy8vTzmZJE3GWB/WcSn4YR2StH3jfljHZXnmLkmts9wlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lq0MhyT3J9kkGS40meTnLHBjNvT/JkkmNJPpTkjZcmriRpHHvGmDkN3FVVR5JcBRxO8lhVHV8z8yzwlVX1r0m+FngAeNMlyCtJGsPIcq+qk8DJ4e2XkpwArgWOr5n50Jrf8mfAdRPOKUnahm2tuSfZB9wIPLHF2DuA37vwSJKkizXOsgwASa4EHgHurKoXN5lZZLXcv2KT/bcDtwPs3bt322ElSeMZ68w9yRWsFvvDVXVok5kvBt4DvK2q/mWjmap6oKrmq2p+bm7uQjNLkkYY52qZAA8CJ6rq3k1m9gKHgFur6q8nG1GStF3jLMvcBNwKHEtydLjtHmAvQFXdD/wo8KnAL61+L+B0Vc1PPq4kaRzjXC3zOJARM98LfO+kQkmSLo6vUJWkBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3KVdZGlpicFgcM62wWDA0tLSlBJpVlnu0i6ysLBAp9M5W/CDwYBOp8PCwsKUk2nW7Jl2AEnjW1xcpN/v0+l06Ha79Ho9+v0+i4uL046mGeOZu7TLLC4u0u12OXjwIN1u12LXhix3aZcZDAb0ej32799Pr9c7bw1eAstd2lXOrLH3+30OHDhwdonGgtd6lru0iywvL5+zxn5mDX55eXnKyTRrUlVTeeL5+flaWVmZynNL0m6V5HBVzY+aG3nmnuT6JIMkx5M8neSODWaS5BeTPJPkySRfcqHBJUkXb5xLIU8Dd1XVkSRXAYeTPFZVx9fMfC3wucOvNwG94a+SpCkYeeZeVSer6sjw9kvACeDadWNvA36tVv0Z8Jok10w8rSRpLNv6gWqSfcCNwBPrdl0L/OOa+89x/jcASdIOGbvck1wJPALcWVUvXsiTJbk9yUqSlVOnTl3IQ0iSxjBWuSe5gtVif7iqDm0w8lHg+jX3rxtuO0dVPVBV81U1Pzc3dyF5JUljGOdqmQAPAieq6t5Nxt4PfNfwqpk3A/9eVScnmFOStA3jXC1zE3ArcCzJ0eG2e4C9AFV1P/C7wNcBzwD/Bdw2+aiSpHGNLPeqehzIiJkC3jmpUJKki+PbD0hSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1KCR5Z7kV5K8kOSpTfa/OskHknw4ydNJbpt8TEnSdoxz5v4QcMsW+98JHK+qNwI3Az+b5JUXH02SdKFGlntVfRD4+FYjwFVJAlw5nD09mXiSpAsxiTX3+4AvAJ4HjgF3VNXLGw0muT3JSpKVU6dOTeCpJUkbmUS5vxU4CnwGcANwX5JXbTRYVQ9U1XxVzc/NzU3gqSVJG5lEud8GHKpVzwDPAm+YwONKki7QJMr9I8BXAyR5PfD5wN9N4HElSRdoz6iBJL/B6lUwVyd5Dvgx4AqAqrofOAg8lOQYEODuqvrYJUssSRppZLlX1beP2P888JaJJZIkXbRd8wrVpaUlBoPBOdsGgwFLS0tTSiRJs2vXlPvCwgKdTudswQ8GAzqdDgsLC1NOJkmzZ+SyzKxYXFyk3+/T6XTodrv0ej36/T6Li4vTjiZJM2fXnLnDasF3u10OHjxIt9u12CVpE7uq3AeDAb1ej/3799Pr9c5bg5ckrdo15X5mjb3f73PgwIGzSzQWvCSdb9eU+/Ly8jlr7GfW4JeXl6ecTJJmT6pqKk88Pz9fKysrU3luSdqtkhyuqvlRc7vmzF2SND7LXZIaZLlLUoMsd0lqkOUuSQ2a2tUySU4B/3CJn+ZqYDe+/bC5d5a5d5a5L85nVtXIj7KbWrnvhCQr41wyNGvMvbPMvbPMvTNclpGkBlnuktSg1sv9gWkHuEDm3lnm3lnm3gFNr7lL0uWq9TN3SbosNVHuSX4lyQtJnlqz7ceTfDTJ0eHX100z40aSXJ9kkOR4kqeT3DHc/rokjyX5m+Gvr5121rW2yD3TxzzJJyX58yQfHub+ieH2z0ryRJJnkvxmkldOO+t6W2R/KMmza475DdPOul6SVyT5iySPDu/P/PGGDXPP/LFeq4lyBx4Cbtlg+89V1Q3Dr9/d4UzjOA3cVVVfCLwZeGeSLwR+GPijqvpc4I+G92fJZrlhto/5fwNfVVVvBG4AbknyZuBnWM39OcC/Au+YYsbNbJYd4IfWHPOj04u4qTuAE2vu74bjDefnhtk/1mc1Ue5V9UHg49POsV1VdbKqjgxvv8TqX6RrgbcB7x2OvRf4pukk3NgWuWdarfqP4d0rhl8FfBXwW8PtM3e8YcvsMy3JdcDXA+8Z3g+74Hivz70bNVHuW/iBJE8Ol21mamljvST7gBuBJ4DXV9XJ4a5/Al4/pVgjrcsNM37Mh//VPgq8ADwG/C3wb1V1ejjyHDP6jWp99qo6c8x/anjMfy7JJ04x4kZ+HngX8PLw/qeyO473+txnzPKxPkfL5d4DPpvV/8KeBH52unE2l+RK4BHgzqp6ce2+Wr2caSbP0DbIPfPHvKr+t6puAK4Dvgx4w5QjjW199iRfBPwIq3+GBeB1wN1TjHiOJN8AvFBVh6edZTu2yD2zx3ojzZZ7Vf3z8B/Dy8Avs/oPeeYkuYLVgny4qg4NN/9zkmuG+69h9UxtpmyUe7ccc4Cq+jdgAHw58Joke4a7rgM+OrVgY1iT/ZbhEllV1X8Dv8psHfObgG9M8vfA+1hdjvkFZv94n5c7ya/P+LE+T7PlfqYch74ZeGqz2WkZrj8+CJyoqnvX7Ho/8N3D298N/M5OZ9vKZrln/ZgnmUvymuHtTwa+htWfFwyAbxmOzdzxhk2z/+Wak4CwunY9M8e8qn6kqq6rqn3AtwF/XFVvZ8aP9ya5v3OWj/VG9owemX1JfgO4Gbg6yXPAjwE3Dy9VKuDvge+bWsDN3QTcChwbrqUC3AP8NNBP8g5W3zmzM6V8m9ks97fP+DG/BnhvklewemLTr6pHkxwH3pfkJ4G/YPUb16zZLPsfJ5kDAhwFvn+aIcd0N7N/vDfy8G461r5CVZIa1OyyjCRdzix3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIa9H+C0r4Xj2qOegAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## subset to the trained data\n",
    "sub = ma.ceil(perc*N)\n",
    "## create fake data for model\n",
    "noiseSize = 0.05\n",
    "#x_train = np.linspace(-3,3,N)\n",
    "#y_train = np.random.exponential(np.sin(x_train)**2) + np.random.randn(N,1)*noiseSize\n",
    "\n",
    "X = np.random.randint(0,N,sub)\n",
    "X = X.reshape(-1,1)\n",
    "X = X.astype(float)\n",
    "#Y = np.random.randn(sub)\n",
    "#Y = Y.reshape(-1,1)\n",
    "Y = np.sin(12*X) + 0.66*np.cos(25*X)  + np.random.randn(sub,1)*noiseSize + 3\n",
    "#print(X.shape)\n",
    "#print(Y.shape)\n",
    "#print(X)\n",
    "#print(Y)\n",
    "\n",
    "## plot distribution of selected sensors\n",
    "plt.plot(X, Y, 'kx')\n",
    "\n",
    "x_train = X\n",
    "y_train = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>prior</th>\n",
       "      <th>transform</th>\n",
       "      <th>trainable</th>\n",
       "      <th>shape</th>\n",
       "      <th>fixed_shape</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GPR/kern/lengthscales</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPR/kern/variance</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPR/likelihood/variance</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             class prior transform  trainable shape  \\\n",
       "GPR/kern/lengthscales    Parameter  None       +ve       True    ()   \n",
       "GPR/kern/variance        Parameter  None       +ve       True    ()   \n",
       "GPR/likelihood/variance  Parameter  None       +ve       True    ()   \n",
       "\n",
       "                         fixed_shape value  \n",
       "GPR/kern/lengthscales           True   1.0  \n",
       "GPR/kern/variance               True   1.0  \n",
       "GPR/likelihood/variance         True  0.01  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## build model\n",
    "kernel = gpflow.kernels.RBF(1, active_dims=[0], lengthscales=1.0)\n",
    "## build model\n",
    "m = gpflow.models.GPR(x_train, y_train, kern=kernel)\n",
    "m.likelihood.variance = 0.01\n",
    "\n",
    "## view \n",
    "m.as_pandas_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 5.042411\n",
      "  Number of iterations: 29\n",
      "  Number of functions evaluations: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 5.042411\n",
      "  Number of iterations: 29\n",
      "  Number of functions evaluations: 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             class prior transform  trainable shape  \\\n",
      "GPR/kern/lengthscales    Parameter  None       +ve       True    ()   \n",
      "GPR/kern/variance        Parameter  None       +ve       True    ()   \n",
      "GPR/likelihood/variance  Parameter  None       +ve       True    ()   \n",
      "\n",
      "                         fixed_shape                value  \n",
      "GPR/kern/lengthscales           True   141.28076689512338  \n",
      "GPR/kern/variance               True    5.433864860990479  \n",
      "GPR/likelihood/variance         True  0.12086105652680339  \n"
     ]
    }
   ],
   "source": [
    "gpflow.train.ScipyOptimizer().minimize(m)\n",
    "print(m.as_pandas_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define x-values not used for training\n",
    "x_new = np.arange(0,N+1,1)\n",
    "x_new = np.setdiff1d(x_new, x_train)\n",
    "x_new = x_new.reshape(-1,1)\n",
    "#print(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## example: thought exercise\n",
    "## 5 sensor locations: S = [4,5,6,7,8]\n",
    "## total number of sensors to find: k = 2\n",
    "## for each iteration (1:k):\n",
    "    ## for each possible sensor location (y) not in A (S):\n",
    "        ## calculate: corr(y)^2 - corr(yA)*np.linalg.inv(corr(AA))*corr(Ay) / corr(y)^2 - corr(ynA)*np.linalg.inv(corr(nAA))*corr(nAy)\n",
    "    ## select max(store_val)\n",
    "    ## append y to A\n",
    "\n",
    "## possible sensor locations\n",
    "S = x_new\n",
    "## number of sensors to find\n",
    "k = k\n",
    "## selected sensors\n",
    "A = np.array([])\n",
    "#if include_trained == True:\n",
    "#    A = x_train\n",
    "#else:\n",
    "#    A = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## x is np.array or single value\n",
    "def generate_cov_mat(x):\n",
    "    if not isinstance(x, np.ndarray):\n",
    "        x = np.array(x).reshape(-1,1)\n",
    "    ## select the 2nd object and bring up one dimension\n",
    "    cov_mat = m.predict_f_full_cov(x)[1][0,:,:]\n",
    "    return(cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_best_sensors_krause(S, k, A, verbose=False):\n",
    "\n",
    "    ## take out locations already in A before checks\n",
    "    #S = S[np.isin(S, A, invert=True)]\n",
    "    \n",
    "    ## checks\n",
    "    if k > S.shape[0]:\n",
    "        print(\"error! k must be smaller than S\")\n",
    "        return\n",
    "    if k/S.shape[0] > 0.25:\n",
    "        print(\"Recommendation: k should be a significantly small fraction of S\")\n",
    "    \n",
    "    ## print statements\n",
    "    print(\"finding \" + str(k) + \" sensor locations of \" + str(S.shape[0]) + \" possible locations\")\n",
    "    \n",
    "    ## next version: \n",
    "    ## add S + U\n",
    "    ## add for 2-d, 3-d, etc\n",
    "    \n",
    "    ## create definition to generate model\n",
    "    \n",
    "    ## later version:\n",
    "    ## use one full matrix and subset from\n",
    "    \n",
    "    ## additional checks:\n",
    "    ## length of A + k should be less than S\n",
    "    \n",
    "    ## for each sensor to be added:\n",
    "    for j in range(k):\n",
    "        ## find coordinates not already in A to iterate through\n",
    "        Y = S[np.isin(S, A, invert=True)]\n",
    "        ## store the calculated value for each potential coordinate in order to take the max\n",
    "        delta = np.array([])\n",
    "        ## print iteration\n",
    "        print(\"Starting iteration: \" + str(j))\n",
    "    \n",
    "        for y in Y:\n",
    "            ## define how many sensor sites already exist\n",
    "            len_A = A.shape[0]\n",
    "            ## place current y in front of A\n",
    "            yA = np.append(y,A)\n",
    "            ## define possible sensor sites not including y & A\n",
    "            nyA = S[np.isin(S, yA, invert=True)]\n",
    "            ## define how many possible sites\n",
    "            len_nA = nyA.shape[0]\n",
    "            ## place current y in front of not y&A\n",
    "            nyA = np.append(y,nyA)\n",
    "            \n",
    "            ## generate the covariance matrix:\n",
    "            ##    y  A1  A2  ...\n",
    "            ## y\n",
    "            ## A1\n",
    "            ## A2\n",
    "            ## ...\n",
    "            cov_mat_A = generate_cov_mat(yA)\n",
    "            ## select y's covariance\n",
    "            y_cov = cov_mat_A[:1,[0]]\n",
    "        \n",
    "            ## grab covariance values\n",
    "            ## make sure A is not empty\n",
    "            #print(\"Determinant: \" + str(np.linalg.det(cov_mat_A[1:len_A+1, 1:len_A+1])))\n",
    "            \n",
    "            if len_A > 0:\n",
    "                AA_cov = np.linalg.inv(cov_mat_A[1:len_A+1, 1:len_A+1])\n",
    "                yA_cov = cov_mat_A[[0],1:len_A+1]\n",
    "                Ay_cov = yA_cov.T\n",
    "                calc_1 = y_cov**2 - np.dot(np.dot(yA_cov, AA_cov), Ay_cov)\n",
    "            ## if A is empty: ignore the 2nd part of the calculation\n",
    "            else:\n",
    "                calc_1 = y_cov**2\n",
    "            \n",
    "            cov_mat_nA = generate_cov_mat(nyA)\n",
    "            nAA_cov = np.linalg.inv(cov_mat_nA[1:len_nA+1, 1:len_nA+1])\n",
    "            nyA_cov = cov_mat_nA[[0],1:len_nA+1]\n",
    "            nAy_cov = nyA_cov.T\n",
    "        \n",
    "            calc_2 = y_cov**2 - np.dot(np.dot(nyA_cov, nAA_cov), nAy_cov)\n",
    "            value = calc_1 / calc_2\n",
    "            delta = np.append(delta, value)\n",
    "            \n",
    "        y_star = np.array(Y[np.argmax(delta)])\n",
    "        A = np.append(A, y_star)\n",
    "        \n",
    "        if verbose == True:\n",
    "            #print(Y)\n",
    "            #print(delta)\n",
    "            print(\"Max value: \" + str(np.amax(delta)))\n",
    "            print(\"Picking sensor site: \" + str(y_star))\n",
    "    \n",
    "    return(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_sensors = pick_best_sensors_krause(S=x_new, k=k, A=A, verbose=True)\n",
    "best_sensors = best_sensors.reshape(-1,1)\n",
    "print(best_sensors)\n",
    "#added_sensors = best_sensors[np.isin(best_sensors, x_train, invert=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot distribution of sensors\n",
    "#sns.stripplot\n",
    "#sns.stripplot(x=x_train, jitter=0.03, color='blue', alpha=0.5)\n",
    "#sns.stripplot(x=x_new, jitter=0.03, color='green', alpha=0.1)\n",
    "#sns.stripplot(x=added_sensors, jitter=0.03, color='red', alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N = 12\n",
    "#X = np.random.rand(N,1)\n",
    "#Y = np.sin(12*X) + 0.66*np.cos(25*X) + np.random.randn(N,1)*0.1 + 3\n",
    "#print(Y.shape)\n",
    "#print(X.shape)\n",
    "#plt.plot(X, Y, 'kx', mew=2)\n",
    "\n",
    "#k = gpflow.kernels.Matern52(1, lengthscales=0.3)\n",
    "#m = gpflow.models.GPR(X, Y, kern=k)\n",
    "#m.likelihood.variance = 0.01\n",
    "#m.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot(m):\n",
    "    ## true underlying function: dashed line\n",
    "    ## mean: green line\n",
    "    ## shade: sd\n",
    "    ## training points: x's\n",
    "    ## selected sensor points: other shape\n",
    "    xx = np.linspace(0, N, N+1)[:,None]\n",
    "    ## actual function\n",
    "    yy = np.sin(12*xx) + 0.66*np.cos(25*xx)  + np.random.randn(N+1,1)*noiseSize + 3\n",
    "    ## predict values\n",
    "    mean, var = m.predict_y(xx)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    mean_train, var_train = m.predict_y(x_train)\n",
    "    plt.plot(x_train, mean_train, 'ko', mew=2)\n",
    "    \n",
    "    mean_sensors, var_sensors = m.predict_y(best_sensors)\n",
    "    plt.plot(best_sensors, mean_sensors, 'rv', mew=2)\n",
    "    \n",
    "    plt.plot(xx, yy, 'k--', alpha=0.5)\n",
    "    plt.plot(xx, mean, 'g', lw=2)\n",
    "    plt.fill_between(xx[:,0], mean[:,0] - 2*np.sqrt(var[:,0]), mean[:,0] + 2*np.sqrt(var[:,0]), color='green', alpha=0.1)\n",
    "    plt.xlim(0, N)\n",
    "    plt.title('Selected Sensors, N=' + str(N))\n",
    "    plt.savefig('../figures/selected_sensors_' + str(N))\n",
    "plot(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## aggregated over time\n",
    "dta = pd.read_csv(\"../data/kcl_london_model_data_winter_agg_time.csv\", sep=',')\n",
    "params = ['latitude', 'longitude']\n",
    "X = dta[params].values\n",
    "## rescale lat/long and year data\n",
    "X = feature_scaler.fit_transform(X)\n",
    "y = dta.loc[:,'nox'].values\n",
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1981, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting to include the trained sensor points\n",
    "#include_trained = False\n",
    "## set max number\n",
    "N = 50\n",
    "## set number of sensor locations to find\n",
    "k = 5\n",
    "## set percent of N to train on\n",
    "perc = .10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "## subset to the trained data\n",
    "sub = ma.ceil(perc*N)\n",
    "## create fake data for model\n",
    "noiseSize = 0.05\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2)\n",
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "## take sample for training\n",
    "x_train = X[0:sub,:]\n",
    "print(x_train.shape)\n",
    "y_train = y[0:sub,:]\n",
    "print(y_train.shape)\n",
    "\n",
    "## standardize y-values\n",
    "y_train = feature_scaler.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>prior</th>\n",
       "      <th>transform</th>\n",
       "      <th>trainable</th>\n",
       "      <th>shape</th>\n",
       "      <th>fixed_shape</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GPR/kern/lengthscales</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPR/kern/variance</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPR/likelihood/variance</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             class prior transform  trainable shape  \\\n",
       "GPR/kern/lengthscales    Parameter  None       +ve       True    ()   \n",
       "GPR/kern/variance        Parameter  None       +ve       True    ()   \n",
       "GPR/likelihood/variance  Parameter  None       +ve       True    ()   \n",
       "\n",
       "                         fixed_shape value  \n",
       "GPR/kern/lengthscales           True   1.0  \n",
       "GPR/kern/variance               True   1.0  \n",
       "GPR/likelihood/variance         True  0.01  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## build model\n",
    "kernel = gpflow.kernels.RBF(2, active_dims=[0,1], lengthscales=1.0)\n",
    "\n",
    "## build model\n",
    "m = gpflow.models.GPR(x_train, y_train, kern=kernel)\n",
    "m.likelihood.variance = 0.01\n",
    "\n",
    "## view \n",
    "m.as_pandas_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 7.094693\n",
      "  Number of iterations: 19\n",
      "  Number of functions evaluations: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 7.094693\n",
      "  Number of iterations: 19\n",
      "  Number of functions evaluations: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             class prior transform  trainable shape  \\\n",
      "GPR/kern/lengthscales    Parameter  None       +ve       True    ()   \n",
      "GPR/kern/variance        Parameter  None       +ve       True    ()   \n",
      "GPR/likelihood/variance  Parameter  None       +ve       True    ()   \n",
      "\n",
      "                         fixed_shape                 value  \n",
      "GPR/kern/lengthscales           True    0.0679467869989709  \n",
      "GPR/kern/variance               True    0.9894247693472301  \n",
      "GPR/likelihood/variance         True  0.010574390897254548  \n"
     ]
    }
   ],
   "source": [
    "## Run Model\n",
    "## Marginal Liklihood Maximization\n",
    "## picks the most simple model that picks the data the best\n",
    "gpflow.train.ScipyOptimizer().minimize(m)\n",
    "print(m.as_pandas_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 2)\n"
     ]
    }
   ],
   "source": [
    "## define x-values not used for training\n",
    "x_new = X[sub+1:N+1,:]\n",
    "print(x_new.shape)\n",
    "#x_new = x_new.reshape(-1,1)\n",
    "#print(x_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "## possible sensor locations, assign index of locations\n",
    "S = np.arange(0,x_new.shape[0]).reshape(x_new.shape[0],1)\n",
    "## number of sensors to find\n",
    "k = k\n",
    "## selected sensors (indices)\n",
    "A = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "## x is np.array or single value\n",
    "def generate_cov_mat(x):\n",
    "    if not isinstance(x, np.ndarray):\n",
    "        x = np.array(x).reshape(-1,1)\n",
    "    cov_mat = m.predict_f_full_cov(x)[1][0,:,:]\n",
    "    return(cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 1)\n",
      "[[ 0]\n",
      " [ 1]\n",
      " [ 2]\n",
      " [ 3]\n",
      " [ 4]\n",
      " [ 5]\n",
      " [ 6]\n",
      " [ 7]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [10]\n",
      " [11]\n",
      " [12]\n",
      " [13]\n",
      " [14]\n",
      " [15]\n",
      " [16]\n",
      " [17]\n",
      " [18]\n",
      " [19]\n",
      " [20]\n",
      " [21]\n",
      " [22]\n",
      " [23]\n",
      " [24]\n",
      " [25]\n",
      " [26]\n",
      " [27]\n",
      " [28]\n",
      " [29]\n",
      " [30]\n",
      " [31]\n",
      " [32]\n",
      " [33]\n",
      " [34]\n",
      " [35]\n",
      " [36]\n",
      " [37]\n",
      " [38]\n",
      " [39]\n",
      " [40]\n",
      " [41]\n",
      " [42]\n",
      " [43]\n",
      " [44]]\n"
     ]
    }
   ],
   "source": [
    "print(S.shape)\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define how many sensor sites already exist\n",
    "len_A = A.shape[0]\n",
    "## place current y in front of A\n",
    "yA = np.append(y,A)\n",
    "## define possible sensor sites not including y & A\n",
    "nyA = S[np.isin(S, yA, invert=True)]\n",
    "## define how many possible sites\n",
    "len_nA = nyA.shape[0]\n",
    "## place current y in front of not y&A\n",
    "nyA = np.append(y,nyA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "[ 0  1  2  4  5  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([3,6])\n",
    "print(A.shape)\n",
    "\n",
    "Y = S[np.isin(S, A, invert=True)]\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.48798828  1.34477407]\n",
      " [ 0.82437672 -1.76280432]\n",
      " [ 0.16312761 -1.56452644]\n",
      " [-0.17799189 -1.17235838]\n",
      " [-1.37062053 -1.1195667 ]\n",
      " [-2.02159418 -1.05759909]\n",
      " [-2.0213646  -1.05604121]\n",
      " [ 0.09762246 -0.90463169]\n",
      " [-0.12725477 -0.83664993]\n",
      " [-0.32341918 -0.70989532]\n",
      " [-0.12312478 -0.62249236]\n",
      " [-2.14595822 -0.44405241]\n",
      " [-0.7016957  -0.41601461]\n",
      " [-0.07952891 -0.33743054]\n",
      " [-0.20799701 -0.27116497]\n",
      " [-0.02163191 -0.24532959]\n",
      " [ 0.23941884 -0.00787962]\n",
      " [ 1.67932657  0.01494142]\n",
      " [-0.89576444  0.02582487]\n",
      " [-2.19542134  0.04987496]\n",
      " [ 0.87396724  0.0613686 ]\n",
      " [-2.00951264  0.18637943]\n",
      " [ 2.41962587  0.26452075]\n",
      " [-1.20529908  0.32037006]\n",
      " [ 1.57345787  0.36638916]\n",
      " [-0.29544402  0.40139434]\n",
      " [ 1.82128316  0.4774572 ]\n",
      " [ 0.35085396  0.53225715]\n",
      " [ 0.59082036  0.78693162]\n",
      " [-0.27150255  0.79961178]\n",
      " [ 1.02282961  0.82596897]\n",
      " [-1.50124807  0.90992904]\n",
      " [-1.51211053  0.92070587]\n",
      " [ 1.21208729  0.99692283]\n",
      " [-0.70385201  1.34534684]\n",
      " [ 1.15421576  1.94022222]\n",
      " [ 0.32311215  2.10811913]\n",
      " [-0.06670784 -2.13222363]\n",
      " [-0.27894059 -1.82081984]\n",
      " [-1.21338351 -1.39963827]\n",
      " [ 1.41923996 -0.9529037 ]\n",
      " [-2.15274228 -0.255502  ]\n",
      " [ 2.30178436  0.37935886]\n",
      " [-0.76309309  1.25090298]\n",
      " [-0.34550153  1.65253019]]\n"
     ]
    }
   ],
   "source": [
    "print(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3, 2)\n",
      "[[ 1.48798828  1.34477407]\n",
      " [-0.17799189 -1.17235838]\n",
      " [-2.0213646  -1.05604121]]\n"
     ]
    }
   ],
   "source": [
    "X = x_new\n",
    "y = 0\n",
    "A = np.array([3,6])\n",
    "\n",
    "yA = np.append(np.array([y]), A, axis=0)\n",
    "print(yA.shape)\n",
    "yA_val = x_new[yA,:].reshape(yA.shape[0],x_new.shape[1])\n",
    "print(yA_val.shape)\n",
    "\n",
    "#y_val = X[y,:].reshape(1,x_new.shape[1])\n",
    "#A_val = x_new[A,:]\n",
    "#print(y_val)\n",
    "#print(x_new)\n",
    "#print(A)\n",
    "#print(A_val.shape)\n",
    "#print(y_val.shape)\n",
    "#print(A_val)\n",
    "#print(y_val)\n",
    "\n",
    "#yA = np.append(y_val, A_val, axis=0)\n",
    "#print(yA.shape)\n",
    "print(yA_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42,)\n",
      "[ 1  2  4  5  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]\n",
      "(43,)\n",
      "(43, 2)\n"
     ]
    }
   ],
   "source": [
    "nyA = S[np.isin(S, yA, invert=True)]\n",
    "print(nyA.shape)\n",
    "print(nyA)\n",
    "nyA = np.append(np.array([y]), nyA, axis=0)\n",
    "print(nyA.shape)\n",
    "nyA_val = x_new[nyA,:].reshape(nyA.shape[0],x_new.shape[1])\n",
    "print(nyA_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "print(yA_val.shape)\n",
    "cov_mat_A = generate_cov_mat(yA_val)\n",
    "print(cov_mat_A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_best_sensors_krause(S, X, k, A, verbose=False):\n",
    "\n",
    "    ## take out locations already in A before checks\n",
    "    #S = S[np.isin(S, A, invert=True)]\n",
    "    \n",
    "    ## checks\n",
    "    if k > S.shape[0]:\n",
    "        print(\"error! k must be smaller than S\")\n",
    "        return\n",
    "    if k/S.shape[0] > 0.25:\n",
    "        print(\"Recommendation: k should be a significantly small fraction of S\")\n",
    "    \n",
    "    ## print statements\n",
    "    print(\"finding \" + str(k) + \" sensor locations of \" + str(S.shape[0]) + \" possible locations\")\n",
    "    \n",
    "    ## next version: \n",
    "    ## add S + U\n",
    "    ## add for 2-d, 3-d, etc\n",
    "    \n",
    "    ## create definition to generate model\n",
    "    \n",
    "    ## later version:\n",
    "    ## use one full matrix and subset from\n",
    "    \n",
    "    ## additional checks:\n",
    "    ## length of A + k should be less than S\n",
    "    \n",
    "    \n",
    "    ## for each sensor to be added:\n",
    "    for j in range(k):\n",
    "        ## find coordinates not already in A to iterate through\n",
    "        Y = S[np.isin(S, A, invert=True)]\n",
    "        ## store the calculated value for each potential coordinate in order to take the max\n",
    "        delta = np.array([])\n",
    "        ## print iteration\n",
    "        print(\"Starting iteration: \" + str(j))\n",
    "    \n",
    "        for y in Y:\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            ## define how many sensor sites already exist\n",
    "            len_A = A.shape[0]\n",
    "            ## place current y in front of A\n",
    "            yA = np.append(y,A)\n",
    "            ## define possible sensor sites not including y & A\n",
    "            nyA = S[np.isin(S, yA, invert=True)]\n",
    "            ## define how many possible sites\n",
    "            len_nA = nyA.shape[0]\n",
    "            ## place current y in front of not y&A\n",
    "            nyA = np.append(y,nyA)\n",
    "            \n",
    "            ## generate the covariance matrix:\n",
    "            ##    y  A1  A2  ...\n",
    "            ## y\n",
    "            ## A1\n",
    "            ## A2\n",
    "            ## ...\n",
    "            cov_mat_A = generate_cov_mat(yA)\n",
    "            ## select y's covariance\n",
    "            y_cov = cov_mat_A[:1,[0]]\n",
    "        \n",
    "            ## grab covariance values\n",
    "            ## make sure A is not empty\n",
    "            #print(\"Determinant: \" + str(np.linalg.det(cov_mat_A[1:len_A+1, 1:len_A+1])))\n",
    "            \n",
    "            if len_A > 0:\n",
    "                AA_cov = np.linalg.inv(cov_mat_A[1:len_A+1, 1:len_A+1])\n",
    "                yA_cov = cov_mat_A[[0],1:len_A+1]\n",
    "                Ay_cov = yA_cov.T\n",
    "                calc_1 = y_cov**2 - np.dot(np.dot(yA_cov, AA_cov), Ay_cov)\n",
    "            ## if A is empty: ignore the 2nd part of the calculation\n",
    "            else:\n",
    "                calc_1 = y_cov**2\n",
    "            \n",
    "            cov_mat_nA = generate_cov_mat(nyA)\n",
    "            nAA_cov = np.linalg.inv(cov_mat_nA[1:len_nA+1, 1:len_nA+1])\n",
    "            nyA_cov = cov_mat_nA[[0],1:len_nA+1]\n",
    "            nAy_cov = nyA_cov.T\n",
    "        \n",
    "            calc_2 = y_cov**2 - np.dot(np.dot(nyA_cov, nAA_cov), nAy_cov)\n",
    "            value = calc_1 / calc_2\n",
    "            delta = np.append(delta, value)\n",
    "            \n",
    "        y_star = np.array(Y[np.argmax(delta)])\n",
    "        A = np.append(A, y_star)\n",
    "        \n",
    "        if verbose == True:\n",
    "            #print(Y)\n",
    "            #print(delta)\n",
    "            print(\"Max value: \" + str(np.amax(delta)))\n",
    "            print(\"Picking sensor site: \" + str(y_star))\n",
    "    \n",
    "    return(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0]\n",
      " [ 1  1]\n",
      " [ 2  2]\n",
      " [ 3  3]\n",
      " [ 4  4]\n",
      " [ 5  5]\n",
      " [ 6  6]\n",
      " [ 7  7]\n",
      " [ 8  8]\n",
      " [ 9  9]\n",
      " [10 10]\n",
      " [11 11]\n",
      " [12 12]\n",
      " [13 13]\n",
      " [14 14]\n",
      " [15 15]\n",
      " [16 16]\n",
      " [17 17]\n",
      " [18 18]\n",
      " [19 19]]\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randint(0,20,N)\n",
    "\n",
    "a1 = np.arange(0,20,1)\n",
    "a2 = np.arange(0,20,1)\n",
    "\n",
    "com = np.vstack((a1, a2)).T\n",
    "com.shape\n",
    "print(com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
