{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load in relevant packages\n",
    "%matplotlib inline\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('seaborn-whitegrid')\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import gpflow\n",
    "import math as ma\n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "## setting to include the trained sensor points\n",
    "#include_trained = False\n",
    "## set max number\n",
    "N = 500\n",
    "## set number of sensor locations to find\n",
    "k = 20\n",
    "## set percent of N to train on\n",
    "perc = .10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## subset to the trained data\n",
    "sub = ma.ceil(perc*N)\n",
    "## create fake data for model\n",
    "noiseSize = 0.05\n",
    "#x_train = np.linspace(-3,3,N)\n",
    "#y_train = np.random.exponential(np.sin(x_train)**2) + np.random.randn(N,1)*noiseSize\n",
    "\n",
    "X = np.random.randint(0,N,sub)\n",
    "X = X.reshape(-1,1)\n",
    "X = X.astype(float)\n",
    "#Y = np.random.randn(sub)\n",
    "#Y = Y.reshape(-1,1)\n",
    "Y = np.sin(12*X) + 0.66*np.cos(25*X)  + np.random.randn(sub,1)*noiseSize + 3\n",
    "#print(X.shape)\n",
    "#print(Y.shape)\n",
    "#print(X)\n",
    "#print(Y)\n",
    "\n",
    "## plot distribution of selected sensors\n",
    "plt.plot(X, Y, 'kx')\n",
    "\n",
    "x_train = X\n",
    "y_train = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build model\n",
    "kernel = gpflow.kernels.RBF(1, active_dims=[0], lengthscales=1.0)\n",
    "## build model\n",
    "m = gpflow.models.GPR(x_train, y_train, kern=kernel)\n",
    "m.likelihood.variance = 0.01\n",
    "\n",
    "## view \n",
    "m.as_pandas_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpflow.train.ScipyOptimizer().minimize(m)\n",
    "print(m.as_pandas_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create covariance matrix for new sensor locations\n",
    "x_new = np.arange(0,N+1,1)\n",
    "x_new = np.setdiff1d(x_new, x_train)\n",
    "x_new = x_new.reshape(-1,1)\n",
    "#print(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## example: thought exercise\n",
    "## 5 sensor locations: S = [4,5,6,7,8]\n",
    "## total number of sensors to find: k = 2\n",
    "## for each iteration (1:k):\n",
    "    ## for each possible sensor location (y) not in A (S):\n",
    "        ## calculate: corr(y)^2 - corr(yA)*np.linalg.inv(corr(AA))*corr(Ay) / corr(y)^2 - corr(ynA)*np.linalg.inv(corr(nAA))*corr(nAy)\n",
    "    ## select max(store_val)\n",
    "    ## append y to A\n",
    "\n",
    "## possible sensor locations\n",
    "S = x_new\n",
    "## number of sensors to find\n",
    "k = k\n",
    "## selected sensors\n",
    "A = np.array([])\n",
    "#if include_trained == True:\n",
    "#    A = x_train\n",
    "#else:\n",
    "#    A = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## x is np.array or single value\n",
    "def generate_cov_mat(x):\n",
    "    x = np.array(x).reshape(-1,1)\n",
    "    cov_mat = m.predict_f_full_cov(x)[1][0,:,:]\n",
    "    return(cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_best_sensors_krause(S, k, A, verbose=False):\n",
    "\n",
    "    ## take out locations already in A before checks\n",
    "    #S = S[np.isin(S, A, invert=True)]\n",
    "    \n",
    "    ## checks\n",
    "    if k > S.shape[0]:\n",
    "        print(\"error! k must be smaller than S\")\n",
    "        return\n",
    "    if k/S.shape[0] > 0.25:\n",
    "        print(\"Recommendation: k should be a significantly small fraction of S\")\n",
    "    \n",
    "    ## print statements\n",
    "    print(\"finding \" + str(k) + \" sensor locations of \" + str(S.shape[0]) + \" possible locations\")\n",
    "    \n",
    "## Question for Youssef: What should I expect? How to check that it's working properly?\n",
    "    \n",
    "    ## next version: \n",
    "    ## add S + U\n",
    "    ## add for 2-d, 3-d, etc\n",
    "    \n",
    "    ## create definition to generate model\n",
    "    \n",
    "    ## later version:\n",
    "    ## use one full matrix and subset from\n",
    "    \n",
    "    ## additional checks:\n",
    "    ## length of A + k should be less than S\n",
    "    \n",
    "    ## for each sensor to be added:\n",
    "    for j in range(k):\n",
    "        ## find coordinates not already in A to iterate through\n",
    "        Y = S[np.isin(S, A, invert=True)]\n",
    "        ## store the calculated value for each potential coordinate in order to take the max\n",
    "        delta = np.array([])\n",
    "        ## print iteration\n",
    "        print(\"Starting iteration: \" + str(j))\n",
    "    \n",
    "        for y in Y:\n",
    "            ## define how many sensor sites already exist\n",
    "            len_A = A.shape[0]\n",
    "            ## place current y in front of A\n",
    "            yA = np.append(y,A)\n",
    "            ## define possible sensor sites not including y & A\n",
    "            nyA = S[np.isin(S, yA, invert=True)]\n",
    "            ## define how many possible sites\n",
    "            len_nA = nyA.shape[0]\n",
    "            ## place current y in front of not y&A\n",
    "            nyA = np.append(y,nyA)\n",
    "            \n",
    "            ## generate the covariance matrix:\n",
    "            ##    y  A1  A2  ...\n",
    "            ## y\n",
    "            ## A1\n",
    "            ## A2\n",
    "            ## ...\n",
    "            cov_mat_A = generate_cov_mat(yA)\n",
    "            ## select y's covariance\n",
    "            y_cov = cov_mat_A[:1,[0]]\n",
    "        \n",
    "            ## grab covariance values\n",
    "            ## make sure A is not empty\n",
    "            #print(\"Determinant: \" + str(np.linalg.det(cov_mat_A[1:len_A+1, 1:len_A+1])))\n",
    "            \n",
    "            if len_A > 0:\n",
    "                AA_cov = np.linalg.inv(cov_mat_A[1:len_A+1, 1:len_A+1])\n",
    "                yA_cov = cov_mat_A[[0],1:len_A+1]\n",
    "                Ay_cov = yA_cov.T\n",
    "                calc_1 = y_cov**2 - np.dot(np.dot(yA_cov, AA_cov), Ay_cov)\n",
    "            ## if A is empty: ignore the 2nd part of the calculation\n",
    "            else:\n",
    "                calc_1 = y_cov**2\n",
    "            \n",
    "            cov_mat_nA = generate_cov_mat(nyA)\n",
    "            nAA_cov = np.linalg.inv(cov_mat_nA[1:len_nA+1, 1:len_nA+1])\n",
    "            nyA_cov = cov_mat_nA[[0],1:len_nA+1]\n",
    "            nAy_cov = nyA_cov.T\n",
    "        \n",
    "            calc_2 = y_cov**2 - np.dot(np.dot(nyA_cov, nAA_cov), nAy_cov)\n",
    "            value = calc_1 / calc_2\n",
    "            delta = np.append(delta, value)\n",
    "            \n",
    "        y_star = np.array(Y[np.argmax(delta)])\n",
    "        A = np.append(A, y_star)\n",
    "        \n",
    "        if verbose == True:\n",
    "            #print(Y)\n",
    "            #print(delta)\n",
    "            print(\"Max value: \" + str(np.amax(delta)))\n",
    "            print(\"Picking sensor site: \" + str(y_star))\n",
    "    \n",
    "    return(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_sensors = pick_best_sensors_krause(S=x_new, k=k, A=A, verbose=True)\n",
    "best_sensors = best_sensors.reshape(-1,1)\n",
    "print(best_sensors)\n",
    "#added_sensors = best_sensors[np.isin(best_sensors, x_train, invert=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot distribution of sensors\n",
    "#sns.stripplot\n",
    "#sns.stripplot(x=x_train, jitter=0.03, color='blue', alpha=0.5)\n",
    "#sns.stripplot(x=x_new, jitter=0.03, color='green', alpha=0.1)\n",
    "#sns.stripplot(x=added_sensors, jitter=0.03, color='red', alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N = 12\n",
    "#X = np.random.rand(N,1)\n",
    "#Y = np.sin(12*X) + 0.66*np.cos(25*X) + np.random.randn(N,1)*0.1 + 3\n",
    "#print(Y.shape)\n",
    "#print(X.shape)\n",
    "#plt.plot(X, Y, 'kx', mew=2)\n",
    "\n",
    "#k = gpflow.kernels.Matern52(1, lengthscales=0.3)\n",
    "#m = gpflow.models.GPR(X, Y, kern=k)\n",
    "#m.likelihood.variance = 0.01\n",
    "#m.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot(m):\n",
    "    ## true underlying function: dashed line\n",
    "    ## mean: green line\n",
    "    ## shade: sd\n",
    "    ## training points: x's\n",
    "    ## selected sensor points: other shape\n",
    "    xx = np.linspace(0, N, N+1)[:,None]\n",
    "    ## actual function\n",
    "    yy = np.sin(12*xx) + 0.66*np.cos(25*xx)  + np.random.randn(N+1,1)*noiseSize + 3\n",
    "    ## predict values\n",
    "    mean, var = m.predict_y(xx)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    mean_train, var_train = m.predict_y(x_train)\n",
    "    plt.plot(x_train, mean_train, 'ko', mew=2)\n",
    "    \n",
    "    mean_sensors, var_sensors = m.predict_y(best_sensors)\n",
    "    plt.plot(best_sensors, mean_sensors, 'rv', mew=2)\n",
    "    \n",
    "    plt.plot(xx, yy, 'k--', alpha=0.5)\n",
    "    plt.plot(xx, mean, 'g', lw=2)\n",
    "    plt.fill_between(xx[:,0], mean[:,0] - 2*np.sqrt(var[:,0]), mean[:,0] + 2*np.sqrt(var[:,0]), color='green', alpha=0.1)\n",
    "    plt.xlim(0, N)\n",
    "    plt.title('Selected Sensors, N=' + str(N))\n",
    "    plt.savefig('../figures/selected_sensors_' + str(N))\n",
    "plot(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for 1,000 possible placements:\n",
    "## [20. 19. 21. 18. 46.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## start 2-d testing\n",
    "x_new2 = np.array(np.arange(0,21,1), np.arange(0,21,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## aggregated over time\n",
    "dta = pd.read_csv(\"../data/kcl_london_model_data_winter_agg_time.csv\", sep=',')\n",
    "params = ['latitude', 'longitude']\n",
    "X = dta[params].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = X[0:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randint(0,20,N)\n",
    "\n",
    "a1 = np.arange(0,20,1)\n",
    "a2 = np.arange(0,20,1)\n",
    "\n",
    "com = np.vstack((a1, a2)).T\n",
    "com.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
