{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load in relevant packages\n",
    "%matplotlib inline\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('seaborn-whitegrid')\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import gpflow\n",
    "import math as ma\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "feature_scaler = StandardScaler()\n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "## set max number\n",
    "N = 5\n",
    "## set number of sensor locations to find\n",
    "k = 1\n",
    "## set percent of N to train on\n",
    "perc = .10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12db85e80>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## create subset size for the trained data\n",
    "sub = ma.ceil(perc*N)\n",
    "## create fake data for model\n",
    "noiseSize = 0.05\n",
    "\n",
    "## define X values (integers from 0 to N)\n",
    "X = np.arange(20,20+N+1,1)\n",
    "## take sample for training\n",
    "x_train = np.random.randint(20,20+N+1,sub)\n",
    "x_train = x_train.reshape(-1,1)\n",
    "x_train = x_train.astype(float)\n",
    "y_train = np.sin(12*x_train) + 0.66*np.cos(25*x_train)  + np.random.randn(sub,1)*noiseSize + 3\n",
    "\n",
    "## plot distribution of selected sensors\n",
    "plt.plot(x_train, y_train, 'kx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>prior</th>\n",
       "      <th>transform</th>\n",
       "      <th>trainable</th>\n",
       "      <th>shape</th>\n",
       "      <th>fixed_shape</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GPR/kern/lengthscales</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPR/kern/variance</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPR/likelihood/variance</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             class prior transform  trainable shape  \\\n",
       "GPR/kern/lengthscales    Parameter  None       +ve       True    ()   \n",
       "GPR/kern/variance        Parameter  None       +ve       True    ()   \n",
       "GPR/likelihood/variance  Parameter  None       +ve       True    ()   \n",
       "\n",
       "                         fixed_shape value  \n",
       "GPR/kern/lengthscales           True   1.0  \n",
       "GPR/kern/variance               True   1.0  \n",
       "GPR/likelihood/variance         True  0.01  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## build model\n",
    "kernel = gpflow.kernels.RBF(1, active_dims=[0], lengthscales=1.0)\n",
    "## build model\n",
    "m = gpflow.models.GPR(x_train, y_train, kern=kernel)\n",
    "m.likelihood.variance = 0.01\n",
    "\n",
    "## view \n",
    "m.as_pandas_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 2.062837\n",
      "  Number of iterations: 8\n",
      "  Number of functions evaluations: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 2.062837\n",
      "  Number of iterations: 8\n",
      "  Number of functions evaluations: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             class prior transform  trainable shape  \\\n",
      "GPR/kern/lengthscales    Parameter  None       +ve       True    ()   \n",
      "GPR/kern/variance        Parameter  None       +ve       True    ()   \n",
      "GPR/likelihood/variance  Parameter  None       +ve       True    ()   \n",
      "\n",
      "                         fixed_shape                value  \n",
      "GPR/kern/lengthscales           True                  1.0  \n",
      "GPR/kern/variance               True   3.6143208919565915  \n",
      "GPR/likelihood/variance         True  0.01034049090229013  \n"
     ]
    }
   ],
   "source": [
    "gpflow.train.ScipyOptimizer().minimize(m)\n",
    "print(m.as_pandas_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## example: thought exercise\n",
    "## 5 sensor locations: S = [4,5,6,7,8]\n",
    "## total number of sensors to find: k = 2\n",
    "## for each iteration (1:k):\n",
    "    ## for each possible sensor location (y) not in A (S):\n",
    "        ## calculate: corr(y)^2 - corr(yA)*np.linalg.inv(corr(AA))*corr(Ay) / corr(y)^2 - corr(ynA)*np.linalg.inv(corr(nAA))*corr(nAy)\n",
    "    ## select max(store_val)\n",
    "    ## append y to A\n",
    "\n",
    "    \n",
    "## selected sensors (indices)\n",
    "A = np.array([],dtype=int)\n",
    "## number of sensors to find\n",
    "k = k\n",
    "## define x_new as the new points not used for training\n",
    "x_new = np.setdiff1d(X, x_train)\n",
    "x_new = x_new.reshape(-1,1)\n",
    "## define S as the incides of x_new\n",
    "S = np.arange(0,x_new.shape[0]).reshape(x_new.shape[0],1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## x is np.array or single value\n",
    "def generate_cov_mat(x):\n",
    "    if not isinstance(x, np.ndarray):\n",
    "        x = np.array(x).reshape(-1,1)\n",
    "    ## select the 2nd object and bring up one dimension\n",
    "    cov_mat = m.predict_f_full_cov(x)[1][0,:,:]\n",
    "    return(cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WORKS ONLY FOR 1-D DATA\n",
    "def plot_as_you_go(m, N, j, A, x_train, y_train, delta, X):\n",
    "    \n",
    "    ## where:\n",
    "    ## m = model object\n",
    "    ## N = max value of X\n",
    "    ## j = iteration of sensor being picked\n",
    "    ## A = best sensors picked so far\n",
    "    ## x_train = x training data\n",
    "    ## y_train = y training data\n",
    "    \n",
    "    ## true underlying function: dashed line\n",
    "    ## mean: green line\n",
    "    ## shade: sd\n",
    "    ## training points: black dots\n",
    "    ## selected sensor points: pink triangles\n",
    "    \n",
    "    ## so the footballs should be based on numerator, should match predicted variance in very beginning.\n",
    "    \n",
    "    ## define entire range of X\n",
    "    #xx = np.linspace(0, N, N+1)[:,None]\n",
    "    N = X.shape[0]\n",
    "    xx = X\n",
    "    ## actual function for entire range of X\n",
    "    yy = np.sin(12*xx) + 0.66*np.cos(25*xx)  + np.random.randn(N,1)*noiseSize + 3\n",
    "    \n",
    "    ## predict values for entire range of X\n",
    "    mean, var = m.predict_y(xx)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    ## display training data\n",
    "    mean_train, var_train = m.predict_y(x_train)\n",
    "    plt.plot(x_train, mean_train, 'ko', mew=2, alpha=0.55)\n",
    "    \n",
    "    ## display best sensors\n",
    "    mean_sensors, var_sensors = m.predict_y(A)\n",
    "    ## plot the most recently added sensor darker than the others\n",
    "    plt.plot(A[j], mean_sensors[j], color='m', marker='v', mew=2, alpha=1.0)\n",
    "    plt.plot(A[0:j], mean_sensors[0:j], 'mv', mew=2, alpha=0.35)\n",
    "    \n",
    "    plt.plot(xx, yy, 'k--', alpha=0.5)\n",
    "    plt.plot(xx, mean, 'g', lw=2)\n",
    "    #plt.fill_between(xx[:,0], mean[:,0] - 2*np.sqrt(delta[:]), mean[:,0] + 2*np.sqrt(delta[:]), color='green', alpha=0.1)\n",
    "    plt.xlim(-1, N+1)\n",
    "    plt.title('Selected Sensors, N=' + str(N))\n",
    "    plt.savefig('../figures/selected_sensors_' + str(N) + ' k=' + str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_best_sensors_krause(S, X, k, A, x_train, y_train, m=m, N=N, verbose=False):\n",
    "\n",
    "    ## take out locations already in A before checks (iterations)\n",
    "    S = S[np.isin(S, A, invert=True)]\n",
    "    \n",
    "    ## checks\n",
    "    if k > S.shape[0]:\n",
    "        print(\"error! k must be smaller than S\")\n",
    "        return\n",
    "    if k/S.shape[0] > 0.25:\n",
    "        print(\"Recommendation: k should be a significantly small fraction of S\")\n",
    "    \n",
    "    ## print statements\n",
    "    print(\"finding \" + str(k) + \" sensor locations of \" + str(S.shape[0]) + \" possible locations\")\n",
    "    \n",
    "    ## next version: \n",
    "    ## add S + U\n",
    "    \n",
    "    ## later version:\n",
    "    ## create function to generate model\n",
    "    \n",
    "    ## for each sensor to be added:\n",
    "    for j in range(k):\n",
    "        ## find the indices of coordinates not already in A to iterate through\n",
    "        Y = S[np.isin(S, A, invert=True)]\n",
    "        ## store the calculated value for each potential coordinate in order to take the max\n",
    "        delta = np.array([])\n",
    "        var_plot = np.array([])\n",
    "        ## print iteration\n",
    "        print(\"Starting iteration: \" + str(j))\n",
    "    \n",
    "        for y in Y:\n",
    "            ## define how many sensor sites already exist\n",
    "            len_A = A.shape[0]\n",
    "            print(\"length of A: \" + str(len_A))\n",
    "            ## combine indices of y and A\n",
    "            yA = np.append(np.array([y]), A, axis=0)\n",
    "            print(\"yA: \" + str(yA))\n",
    "            ## collect values of y and A using the indices\n",
    "            yA_val = X[yA,:].reshape(yA.shape[0],X.shape[1])\n",
    "            print(\"yA_val: \" + str(yA_val))\n",
    "            \n",
    "            ## define the rest of possible sites taking out y and A\n",
    "            nyA = S[np.isin(S, yA, invert=True)]\n",
    "            len_nA = nyA.shape[0]\n",
    "            print(\"length of nA: \" + str(len_nA))\n",
    "            ## define the indices of locations not in yA\n",
    "            nyA = np.append(np.array([y]), nyA, axis=0)\n",
    "            print(\"nyA: \" + str(nyA))\n",
    "            ## collect values of y and nA using the indices\n",
    "            nyA_val = X[nyA,:].reshape(nyA.shape[0],X.shape[1])\n",
    "            print(\"nyA_val: \" + str(nyA_val))\n",
    "\n",
    "            ## generate the covariance matrix:\n",
    "            ##    y  A1  A2  ...\n",
    "            ## y\n",
    "            ## A1\n",
    "            ## A2\n",
    "            ## ...\n",
    "            cov_mat_A = generate_cov_mat(yA_val)\n",
    "            ## select y's covariance\n",
    "            y_cov = cov_mat_A[:1,[0]]\n",
    "            ## grab covariance values\n",
    "            if len_A > 0:\n",
    "                yA_cov = cov_mat_A[[0],1:len_A+1]\n",
    "                Ay_cov = yA_cov.T\n",
    "                AA_cov = cov_mat_A[1:len_A+1, 1:len_A+1]\n",
    "                ## Mz = x, give M and x and solve for z\n",
    "                AA_cov_inv = np.linalg.solve(AA_cov, Ay_cov)\n",
    "                calc_1 = y_cov**2 - np.dot(yA_cov, AA_cov_inv)\n",
    "                ## old code:\n",
    "                #AA_cov = np.linalg.inv(cov_mat_A[1:len_A+1, 1:len_A+1])\n",
    "                #calc_1 = y_cov**2 - np.dot(np.dot(yA_cov, AA_cov), Ay_cov)\n",
    "            ## if A is empty: ignore the 2nd part of the calculation\n",
    "            else:\n",
    "                calc_1 = y_cov**2\n",
    "            \n",
    "            cov_mat_nA = generate_cov_mat(nyA_val)\n",
    "            print(\"cov_mat_nA: \")\n",
    "            print(cov_mat_nA)\n",
    "            nyA_cov = cov_mat_nA[[0],1:len_nA+1]\n",
    "            print(\"nyA_cov: \")\n",
    "            print(nyA_cov)\n",
    "            nAy_cov = nyA_cov.T\n",
    "            nAA_cov = cov_mat_nA[1:len_nA+1, 1:len_nA+1]\n",
    "            print(\"nAA_cov: \")\n",
    "            print(nAA_cov)\n",
    "            ## Mz = x, give M and x and solve for z\n",
    "            nAA_cov_inv = np.linalg.solve(nAA_cov, nAy_cov)\n",
    "            calc_2 = y_cov**2 - np.dot(nyA_cov, nAA_cov_inv)\n",
    "            ## old code:\n",
    "            #nAA_cov = np.linalg.inv(cov_mat_nA[1:len_nA+1, 1:len_nA+1])\n",
    "            #calc_2 = y_cov**2 - np.dot(np.dot(nyA_cov, nAA_cov), nAy_cov)\n",
    "            \n",
    "            value = calc_1 / calc_2\n",
    "            delta = np.append(delta, value)\n",
    "            \n",
    "            var_plot = np.append(var_plot, calc_1)\n",
    "            \n",
    "        ## find the index with the largest delta\n",
    "        y_star = np.array(Y[np.argmax(delta)])\n",
    "        ## append to A as a new sensor site\n",
    "        A = np.append(A, y_star)\n",
    "        \n",
    "        print(Y.shape)\n",
    "        \n",
    "        ## generate plot\n",
    "        #plot_as_you_go(m, N, j=j-1, A=best_sensors, x_train=x_train, y_train=y_train, delta=var_plot, X=Y.reshape(Y.shape[0],1))\n",
    "        \n",
    "        if verbose == True:\n",
    "            #print(Y)\n",
    "            #print(delta)\n",
    "            print(\"Max value: \" + str(np.amax(delta)))\n",
    "            print(\"Picking sensor site: \" + str(y_star))\n",
    "    \n",
    "    A_sites = X[A,:]\n",
    "    return(A_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "[[20]\n",
      " [21]\n",
      " [22]\n",
      " [24]\n",
      " [25]]\n",
      "[[23.]]\n"
     ]
    }
   ],
   "source": [
    "print(S)\n",
    "print(x_new)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding 1 sensor locations of 5 possible locations\n",
      "Starting iteration: 0\n",
      "length of A: 0\n",
      "yA: [0]\n",
      "yA_val: [[20]]\n",
      "length of nA: 4\n",
      "nyA: [0 1 2 3 4]\n",
      "nyA_val: [[20]\n",
      " [21]\n",
      " [22]\n",
      " [24]\n",
      " [25]]\n",
      "cov_mat_nA: \n",
      "[[ 3.61387612  2.18677803  0.46486151 -0.02307116 -0.00540494]\n",
      " [ 2.18677803  3.54831115  1.89636129 -0.25568367 -0.06479727]\n",
      " [ 0.46486151  1.89636129  2.28847974 -0.83669601 -0.25568367]\n",
      " [-0.02307116 -0.25568367 -0.83669601  2.28847974  1.89636129]\n",
      " [-0.00540494 -0.06479727 -0.25568367  1.89636129  3.54831115]]\n",
      "nyA_cov: \n",
      "[[ 2.18677803  0.46486151 -0.02307116 -0.00540494]]\n",
      "nAA_cov: \n",
      "[[ 3.54831115  1.89636129 -0.25568367 -0.06479727]\n",
      " [ 1.89636129  2.28847974 -0.83669601 -0.25568367]\n",
      " [-0.25568367 -0.83669601  2.28847974  1.89636129]\n",
      " [-0.06479727 -0.25568367  1.89636129  3.54831115]]\n",
      "length of A: 0\n",
      "yA: [1]\n",
      "yA_val: [[21]]\n",
      "length of nA: 4\n",
      "nyA: [1 0 2 3 4]\n",
      "nyA_val: [[21]\n",
      " [20]\n",
      " [22]\n",
      " [24]\n",
      " [25]]\n",
      "cov_mat_nA: \n",
      "[[ 3.54831115  2.18677803  1.89636129 -0.25568367 -0.06479727]\n",
      " [ 2.18677803  3.61387612  0.46486151 -0.02307116 -0.00540494]\n",
      " [ 1.89636129  0.46486151  2.28847974 -0.83669601 -0.25568367]\n",
      " [-0.25568367 -0.02307116 -0.83669601  2.28847974  1.89636129]\n",
      " [-0.06479727 -0.00540494 -0.25568367  1.89636129  3.54831115]]\n",
      "nyA_cov: \n",
      "[[ 2.18677803  1.89636129 -0.25568367 -0.06479727]]\n",
      "nAA_cov: \n",
      "[[ 3.61387612  0.46486151 -0.02307116 -0.00540494]\n",
      " [ 0.46486151  2.28847974 -0.83669601 -0.25568367]\n",
      " [-0.02307116 -0.83669601  2.28847974  1.89636129]\n",
      " [-0.00540494 -0.25568367  1.89636129  3.54831115]]\n",
      "length of A: 0\n",
      "yA: [2]\n",
      "yA_val: [[22]]\n",
      "length of nA: 4\n",
      "nyA: [2 0 1 3 4]\n",
      "nyA_val: [[22]\n",
      " [20]\n",
      " [21]\n",
      " [24]\n",
      " [25]]\n",
      "cov_mat_nA: \n",
      "[[ 2.28847974  0.46486151  1.89636129 -0.83669601 -0.25568367]\n",
      " [ 0.46486151  3.61387612  2.18677803 -0.02307116 -0.00540494]\n",
      " [ 1.89636129  2.18677803  3.54831115 -0.25568367 -0.06479727]\n",
      " [-0.83669601 -0.02307116 -0.25568367  2.28847974  1.89636129]\n",
      " [-0.25568367 -0.00540494 -0.06479727  1.89636129  3.54831115]]\n",
      "nyA_cov: \n",
      "[[ 0.46486151  1.89636129 -0.83669601 -0.25568367]]\n",
      "nAA_cov: \n",
      "[[ 3.61387612  2.18677803 -0.02307116 -0.00540494]\n",
      " [ 2.18677803  3.54831115 -0.25568367 -0.06479727]\n",
      " [-0.02307116 -0.25568367  2.28847974  1.89636129]\n",
      " [-0.00540494 -0.06479727  1.89636129  3.54831115]]\n",
      "length of A: 0\n",
      "yA: [3]\n",
      "yA_val: [[24]]\n",
      "length of nA: 4\n",
      "nyA: [3 0 1 2 4]\n",
      "nyA_val: [[24]\n",
      " [20]\n",
      " [21]\n",
      " [22]\n",
      " [25]]\n",
      "cov_mat_nA: \n",
      "[[ 2.28847974 -0.02307116 -0.25568367 -0.83669601  1.89636129]\n",
      " [-0.02307116  3.61387612  2.18677803  0.46486151 -0.00540494]\n",
      " [-0.25568367  2.18677803  3.54831115  1.89636129 -0.06479727]\n",
      " [-0.83669601  0.46486151  1.89636129  2.28847974 -0.25568367]\n",
      " [ 1.89636129 -0.00540494 -0.06479727 -0.25568367  3.54831115]]\n",
      "nyA_cov: \n",
      "[[-0.02307116 -0.25568367 -0.83669601  1.89636129]]\n",
      "nAA_cov: \n",
      "[[ 3.61387612  2.18677803  0.46486151 -0.00540494]\n",
      " [ 2.18677803  3.54831115  1.89636129 -0.06479727]\n",
      " [ 0.46486151  1.89636129  2.28847974 -0.25568367]\n",
      " [-0.00540494 -0.06479727 -0.25568367  3.54831115]]\n",
      "length of A: 0\n",
      "yA: [4]\n",
      "yA_val: [[25]]\n",
      "length of nA: 4\n",
      "nyA: [4 0 1 2 3]\n",
      "nyA_val: [[25]\n",
      " [20]\n",
      " [21]\n",
      " [22]\n",
      " [24]]\n",
      "cov_mat_nA: \n",
      "[[ 3.54831115 -0.00540494 -0.06479727 -0.25568367  1.89636129]\n",
      " [-0.00540494  3.61387612  2.18677803  0.46486151 -0.02307116]\n",
      " [-0.06479727  2.18677803  3.54831115  1.89636129 -0.25568367]\n",
      " [-0.25568367  0.46486151  1.89636129  2.28847974 -0.83669601]\n",
      " [ 1.89636129 -0.02307116 -0.25568367 -0.83669601  2.28847974]]\n",
      "nyA_cov: \n",
      "[[-0.00540494 -0.06479727 -0.25568367  1.89636129]]\n",
      "nAA_cov: \n",
      "[[ 3.61387612  2.18677803  0.46486151 -0.02307116]\n",
      " [ 2.18677803  3.54831115  1.89636129 -0.25568367]\n",
      " [ 0.46486151  1.89636129  2.28847974 -0.83669601]\n",
      " [-0.02307116 -0.25568367 -0.83669601  2.28847974]]\n",
      "(5,)\n",
      "[[22]]\n"
     ]
    }
   ],
   "source": [
    "best_sensors = pick_best_sensors_krause(S=S, X=x_new, k=k, A=A, x_train=x_train, y_train=y_train, m=m, N=N, verbose=False)\n",
    "print(best_sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Original plot\n",
    "## WORKS ONLY FOR 1-D DATA\n",
    "def plot(m, N):\n",
    "    ## true underlying function: dashed line\n",
    "    ## mean: green line\n",
    "    ## shade: sd\n",
    "    ## training points: black dots\n",
    "    ## selected sensor points: red triangles\n",
    "    xx = np.linspace(0, N, N+1)[:,None]\n",
    "    ## actual function\n",
    "    yy = np.sin(12*xx) + 0.66*np.cos(25*xx)  + np.random.randn(N+1,1)*noiseSize + 3\n",
    "    ## predict values\n",
    "    mean, var = m.predict_y(xx)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    mean_train, var_train = m.predict_y(x_train)\n",
    "    plt.plot(x_train, mean_train, 'ko', mew=2)\n",
    "    \n",
    "    mean_sensors, var_sensors = m.predict_y(best_sensors)\n",
    "    plt.plot(best_sensors, mean_sensors, 'rv', mew=2)\n",
    "    \n",
    "    plt.plot(xx, yy, 'k--', alpha=0.5)\n",
    "    plt.plot(xx, mean, 'g', lw=2)\n",
    "    plt.fill_between(xx[:,0], mean[:,0] - 2*np.sqrt(var[:,0]), mean[:,0] + 2*np.sqrt(var[:,0]), color='green', alpha=0.1)\n",
    "    plt.xlim(0, N)\n",
    "    plt.title('Selected Sensors, N=' + str(N))\n",
    "    plt.savefig('../figures/selected_sensors_' + str(N))\n",
    "plot(m, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_new.shape[1])\n",
    "#print(x_new[0:5,:].reshape(5,1))\n",
    "## combine indices of y and A\n",
    "#yA = np.append(np.array([y]), A, axis=0)\n",
    "## collect values of y and A using the indices\n",
    "#yA_val = X[yA,:].reshape(yA.shape[0],X.shape[1])\n",
    "\n",
    "#print(m.as_pandas_table())\n",
    "#cov_mat_A = generate_cov_mat(x_new[0:5,:].reshape(5,1))\n",
    "#print(cov_mat_A)\n",
    "\n",
    "#m.likelihood.variance = 0.01\n",
    "#print(m.as_pandas_table())\n",
    "#cov_mat_A = generate_cov_mat(x_new[0:5,:].reshape(5,1))\n",
    "#print(cov_mat_A)\n",
    "\n",
    "## Try, artificially: (i) putting the input locations *very* close together;\n",
    "## and (ii) increasing the correlation lengths.\n",
    "## Keep the likelihood variance zero while you're at it.\n",
    "## Could you extract the eigenvalues of the matrix that's causing a problem and list them?\n",
    "## How small is the smallest eigenvalue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([[0,.00000001,.00000002,.00000003], [0,.00000002,.00000003,.00000001]]).reshape(4,2)\n",
    "y_train = np.array([1.3, 2.4, 3.6, 1.0]).reshape(4,1)\n",
    "\n",
    "## build model\n",
    "kernel = gpflow.kernels.RBF(2, active_dims=[0,1], lengthscales=1.0)\n",
    "\n",
    "## build model\n",
    "m = gpflow.models.GPR(x_train, y_train, kern=kernel)\n",
    "m.likelihood.variance = 0.01\n",
    "\n",
    "gpflow.train.ScipyOptimizer().minimize(m)\n",
    "print(m.as_pandas_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m.kern.lengthscales = 5\n",
    "#m.kern.variance = 0\n",
    "#m.likelihood.variance = 0\n",
    "#print(m.as_pandas_table())\n",
    "\n",
    "nyA_val = np.array([[0,.00000001,.00000002,.00000002], [0,.00000002,.00000003,.00000003]]).reshape(4,2)\n",
    "#np.array([[0,.00000001,.00000002,.00000003], [0.00000003, 0.00000002, 0.00000000, 0]]).reshape(4,2)\n",
    "cov_mat_nA = generate_cov_mat(nyA_val)\n",
    "print(cov_mat_nA)\n",
    "print(np.linalg.det(cov_mat_nA))\n",
    "eig_val = np.linalg.eig(cov_mat_nA)\n",
    "eig_val = eig_val[0]\n",
    "print(eig_val.shape)\n",
    "print(np.amin(eig_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fake data\n",
    "## random int X and NO2 concentration Y works!\n",
    "#X = np.random.randint(50, size=(20, 2)).astype(float)\n",
    "## so does this...\n",
    "#X = np.random.normal(size=(20,2))\n",
    "#print(X.shape)\n",
    "#print(X)\n",
    "#dta = pd.read_csv(\"../data/kcl_london_model_data_winter_collapsed.csv\", sep=',') \n",
    "#y = dta.loc[:,'nox'].values\n",
    "#y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1981, 7)\n"
     ]
    }
   ],
   "source": [
    "## aggregated over time\n",
    "#dta = pd.read_csv(\"../data/kcl_london_model_data_winter_collapsed.csv\", sep=',') \n",
    "#print(dta.shape)\n",
    "#params = ['latitude', 'longitude']\n",
    "\n",
    "dta = pd.read_csv(\"../data/kcl_london_model_data_winter_agg_time.csv\", sep=',')\n",
    "print(dta.shape)\n",
    "params = ['latitude', 'longitude', 'year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1981\n",
      "1941\n",
      "(1941, 7)\n"
     ]
    }
   ],
   "source": [
    "print(dta.shape[0])\n",
    "print(dta[params].drop_duplicates().shape[0])\n",
    "dta = dta.drop_duplicates(params)\n",
    "print(dta.shape)\n",
    "#print(X.shape)\n",
    "#unique_elements = np.unique(X)\n",
    "#print(unique_elements[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1941, 3)\n",
      "(1941, 1)\n"
     ]
    }
   ],
   "source": [
    "X = dta[params].values\n",
    "print(X.shape)\n",
    "## rescale lat/long and year data\n",
    "## scaling the data causes the determinant to be 0 for the matrix\n",
    "#X = feature_scaler.fit_transform(X)\n",
    "y = dta.loc[:,'nox'].values\n",
    "y = y.reshape(-1,1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set max number\n",
    "N = 100\n",
    "## set number of sensor locations to find\n",
    "k = 2\n",
    "## set percent of N to train on\n",
    "perc = .10\n",
    "#perc = .75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "## subset to the trained data\n",
    "sub = ma.ceil(perc*N)\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "## take the first sub coordinates for training\n",
    "x_samps = np.arange(0,sub)\n",
    "print(x_samps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X[x_samps,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3)\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "## take sample for training\n",
    "#x_samps = np.random.randint(X.shape[0], size=sub)\n",
    "\n",
    "x_train = X[x_samps,:]\n",
    "y_train = y[x_samps,:]\n",
    "## standardize y-values\n",
    "y_train = feature_scaler.fit_transform(y_train)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>prior</th>\n",
       "      <th>transform</th>\n",
       "      <th>trainable</th>\n",
       "      <th>shape</th>\n",
       "      <th>fixed_shape</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GPR/kern/lengthscales</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPR/kern/variance</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPR/likelihood/variance</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             class prior transform  trainable shape  \\\n",
       "GPR/kern/lengthscales    Parameter  None       +ve       True    ()   \n",
       "GPR/kern/variance        Parameter  None       +ve       True    ()   \n",
       "GPR/likelihood/variance  Parameter  None       +ve       True    ()   \n",
       "\n",
       "                         fixed_shape value  \n",
       "GPR/kern/lengthscales           True   1.0  \n",
       "GPR/kern/variance               True   1.0  \n",
       "GPR/likelihood/variance         True  0.01  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## build model\n",
    "kernel = gpflow.kernels.RBF(2, active_dims=[0,1], lengthscales=1.0)\n",
    "#kernel = gpflow.kernels.RBF(2, active_dims=[0,1], lengthscales=1.0) *\\\n",
    "#            gpflow.kernels.RBF(1 , active_dims=[2], lengthscales=0.1)\n",
    "\n",
    "## build model\n",
    "m = gpflow.models.GPR(x_train, y_train, kern=kernel)\n",
    "m.likelihood.variance = 0.01\n",
    "\n",
    "## could put bounds on likelihood variance to never be below or equal to 0.\n",
    "\n",
    "\n",
    "## view \n",
    "m.as_pandas_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 14.117221\n",
      "  Number of iterations: 20\n",
      "  Number of functions evaluations: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 14.117221\n",
      "  Number of iterations: 20\n",
      "  Number of functions evaluations: 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             class prior transform  trainable shape  \\\n",
      "GPR/kern/lengthscales    Parameter  None       +ve       True    ()   \n",
      "GPR/kern/variance        Parameter  None       +ve       True    ()   \n",
      "GPR/likelihood/variance  Parameter  None       +ve       True    ()   \n",
      "\n",
      "                         fixed_shape                value  \n",
      "GPR/kern/lengthscales           True  0.15382896587882736  \n",
      "GPR/kern/variance               True  0.15634880709162882  \n",
      "GPR/likelihood/variance         True    0.852201139944699  \n"
     ]
    }
   ],
   "source": [
    "## Run Model\n",
    "## Marginal Liklihood Maximization\n",
    "## picks the most simple model that picks the data the best\n",
    "gpflow.train.ScipyOptimizer().minimize(m)\n",
    "print(m.as_pandas_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29\n",
      "  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112]\n",
      "(101, 3)\n",
      "[[ 5.13735678e+01 -2.91725038e-01  2.00000000e+03]\n",
      " [ 5.15066280e+01 -2.67934000e-01  2.00000000e+03]\n",
      " [ 5.14925070e+01 -2.57252000e-01  2.00000000e+03]\n",
      " [ 5.14801890e+01 -2.37335000e-01  2.00000000e+03]\n",
      " [ 5.14927663e+01 -2.23601338e-01  2.00000000e+03]]\n"
     ]
    }
   ],
   "source": [
    "## define x-values not used for training\n",
    "## iterate all of X\n",
    "#X_iter = np.arange(0,X.shape[0])\n",
    "## take out the iters already used for training\n",
    "#x_new = np.setdiff1d(X_iter, x_samps)\n",
    "x_new_samps = np.arange(sub+2,sub+2+N+1)\n",
    "#x_new_samps = np.arange(sub+20, sub+30+20)\n",
    "print(x_new_samps)\n",
    "## randomly select new iterations from the list\n",
    "#x_new_samps = np.random.choice(x_new, N-sub, replace=False)\n",
    "#print(x_samps)\n",
    "#print(x_new_samps)\n",
    "x_new = X[x_new_samps,:]\n",
    "print(x_new.shape)\n",
    "print(x_new[0:5])\n",
    "#print(x_samps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "## selected sensors (indices)\n",
    "A = np.array([],dtype=int)\n",
    "## number of sensors to find\n",
    "k = k\n",
    "## define S as the incides of x_new\n",
    "S = np.arange(0,x_new.shape[0]).reshape(x_new.shape[0],1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "## x is np.array or single value\n",
    "def generate_cov_mat(x):\n",
    "    if not isinstance(x, np.ndarray):\n",
    "        x = np.array(x).reshape(-1,1)\n",
    "    cov_mat = m.predict_f_full_cov(x)[1][0,:,:] #+ (identity * likelihood variance)\n",
    "    eig_val = np.linalg.eigvals(cov_mat)\n",
    "    #print(eig_val)\n",
    "    #eig_val = eig_val[0]\n",
    "    print(np.amin(eig_val))\n",
    "    return(cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_new.shape)\n",
    "#print(X[0,:])\n",
    "m.likelihood.variance = 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "test = np.array([[1,2,3,4], [4,5,2,-1]]).reshape(4,2)\n",
    "print(np.amin(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_best_sensors_krause(S, X, k, A, verbose=False):\n",
    "\n",
    "    ## take out locations already in A before checks\n",
    "    S = S[np.isin(S, A, invert=True)]\n",
    "    \n",
    "    ## collect determinants\n",
    "    det = np.array([])\n",
    "    \n",
    "    ## checks\n",
    "    if k > S.shape[0]:\n",
    "        print(\"error! k must be smaller than S\")\n",
    "        return\n",
    "    if k/S.shape[0] > 0.25:\n",
    "        print(\"Recommendation: k should be a significantly small fraction of S\")\n",
    "    \n",
    "    ## print statements\n",
    "    print(\"finding \" + str(k) + \" sensor locations of \" + str(S.shape[0]) + \" possible locations\")\n",
    "    \n",
    "    ## next version: \n",
    "    ## add S + U\n",
    "    \n",
    "    ## later version:\n",
    "    ## create function to generate model\n",
    "    \n",
    "    ## add order of points selected\n",
    "    ## generate plots as it selects sensors \n",
    "    ## so the footballs should be based on numerator, should match predicted variance in very beginning.\n",
    "    \n",
    "    ## for each sensor to be added:\n",
    "    for j in range(k):\n",
    "        ## find the indices of coordinates not already in A to iterate through\n",
    "        Y = S[np.isin(S, A, invert=True)]\n",
    "        ## store the calculated value for each potential coordinate in order to take the max\n",
    "        delta = np.array([])\n",
    "        ## print iteration\n",
    "        print(\"Starting iteration: \" + str(j))\n",
    "    \n",
    "        for y in Y:\n",
    "            ## define how many sensor sites already exist\n",
    "            len_A = A.shape[0]\n",
    "            ## combine indices of y and A\n",
    "            yA = np.append(np.array([y]), A, axis=0)\n",
    "            ## collect values of y and A using the indices\n",
    "            yA_val = X[yA,:].reshape(yA.shape[0],X.shape[1])\n",
    "            \n",
    "            ## define the rest of possible sites taking out y and A\n",
    "            nyA = S[np.isin(S, yA, invert=True)]\n",
    "            len_nA = nyA.shape[0]\n",
    "            ## define the indices of locations not in yA\n",
    "            nyA = np.append(np.array([y]), nyA, axis=0)\n",
    "            ## collect values of y and nA using the indices\n",
    "            nyA_val = X[nyA,:].reshape(nyA.shape[0],X.shape[1])\n",
    "\n",
    "            ## generate the covariance matrix:\n",
    "            ##    y  A1  A2  ...\n",
    "            ## y\n",
    "            ## A1\n",
    "            ## A2\n",
    "            ## ...\n",
    "            cov_mat_A = generate_cov_mat(yA_val)\n",
    "            ## select y's covariance\n",
    "            y_cov = cov_mat_A[:1,[0]]\n",
    "            ## grab covariance values\n",
    "            if len_A > 0:\n",
    "                yA_cov = cov_mat_A[[0],1:len_A+1]\n",
    "                Ay_cov = yA_cov.T\n",
    "                AA_cov = cov_mat_A[1:len_A+1, 1:len_A+1]\n",
    "                ## Mz = x, give M and x and solve for z\n",
    "                AA_cov_inv = np.linalg.solve(AA_cov, Ay_cov)\n",
    "                calc_1 = y_cov**2 - np.dot(yA_cov, AA_cov_inv)\n",
    "                ## old code:\n",
    "                #AA_cov = np.linalg.inv(cov_mat_A[1:len_A+1, 1:len_A+1])\n",
    "                #calc_1 = y_cov**2 - np.dot(np.dot(yA_cov, AA_cov), Ay_cov)\n",
    "            ## if A is empty: ignore the 2nd part of the calculation\n",
    "            else:\n",
    "                calc_1 = y_cov**2\n",
    "            \n",
    "            cov_mat_nA = generate_cov_mat(nyA_val)\n",
    "            nyA_cov = cov_mat_nA[[0],1:len_nA+1]\n",
    "            nAy_cov = nyA_cov.T\n",
    "            nAA_cov = cov_mat_nA[1:len_nA+1, 1:len_nA+1]\n",
    "            ## Mz = x, give M and x and solve for z\n",
    "            #print(nAA_cov)\n",
    "            nAA_cov_inv = np.linalg.solve(nAA_cov, nAy_cov)\n",
    "            calc_2 = y_cov**2 - np.dot(nyA_cov, nAA_cov_inv)\n",
    "            ## old code:\n",
    "            #nAA_cov = np.linalg.inv(cov_mat_nA[1:len_nA+1, 1:len_nA+1])\n",
    "            #calc_2 = y_cov**2 - np.dot(np.dot(nyA_cov, nAA_cov), nAy_cov)\n",
    "            \n",
    "            value = calc_1 / calc_2\n",
    "            delta = np.append(delta, value)\n",
    "            \n",
    "        ## find the index with the largest delta\n",
    "        y_star = np.array(Y[np.argmax(delta)])\n",
    "        ## append to A as a new sensor site\n",
    "        A = np.append(A, y_star)\n",
    "        \n",
    "        if verbose == True:\n",
    "            #print(Y)\n",
    "            #print(delta)\n",
    "            print(\"Max value: \" + str(np.amax(delta)))\n",
    "            print(\"Picking sensor site: \" + str(y_star))\n",
    "    \n",
    "    A_sites = X[A,:]\n",
    "    return(A_sites, det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m.likelihood.variance = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding 2 sensor locations of 101 possible locations\n",
      "Starting iteration: 0\n",
      "0.11432468168245812\n",
      "(-9.115965534328384e-12+0j)\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-189-05323bbe91bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#print(S.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#print(x_new.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbest_sensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpick_best_sensors_krause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_sensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print(det)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-187-2949a7d2f0fb>\u001b[0m in \u001b[0;36mpick_best_sensors_krause\u001b[0;34m(S, X, k, A, verbose)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;31m## Mz = x, give M and x and solve for z\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;31m#print(nAA_cov)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mnAA_cov_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnAA_cov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnAy_cov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mcalc_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_cov\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnyA_cov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnAA_cov_inv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;31m## old code:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'DD->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'dd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "#print(S.shape)\n",
    "#print(x_new.shape)\n",
    "best_sensors, det = pick_best_sensors_krause(S=S, X=x_new, k=k, A=A, verbose=False)\n",
    "print(best_sensors)\n",
    "#print(det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
